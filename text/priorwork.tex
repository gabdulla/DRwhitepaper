
The prior work described in this paper is that which addresses strategies
that HPC centers can take to manage power. A lot of work has been done on
energy efficiency, some of which has an element of power management. But,
there is not a lot work that is specifically focused on power management in
response to a request from an electrical service provider.

\subsection{Fine Grained Power Management}
In \cite{varma_control-theoretic_2003} (Varma et al., 2003) system level DVFS techniques demonstrated. They
monitor CPU utilization at regular intervals and then perform dynamic
scaling based on their estimate of utilization for the next interval.

Authors in\cite{von_laszewski_power-aware_2009} (von Laszewski et al., 2009) present an efficient scheduling
algorithm to allocate virtual machines in a DVFS-enabled cluster by
dynamically scaling the supplied voltages.

vGreen \cite{dhiman_vgreen:_2009} (Dhiman et al., 2009) is a system for energy efficient computing in
virtualized environments by linking online workload characterization to
dynamic VM scheduling decisions to achieve better performance, energy
efficiency and power balance in the system.


\subsection{Power Capping}

\textbf{Power capping }techniques set a value below the actual peak power
and preventing that number from being exceeded through some type of control
loop [Fan07]. There are numerous ways to implement this, but they generally
consist of a \textbf{power monitoring system }such as a power estimation
method or one based on direct power sensing, and a \textbf{power throttling
mechanism}. Power throttling generally works best when there is \textbf{a
set of jobs with loose service level guarantees or low priority }that can be
forced to reduce consumption when the data center is approaching \textbf{the
power cap value}. Power consumption can be reduced simply by
\textbf{de-scheduling tasks }or by using any available component-level power
management \textbf{knobs}, such as DVFS [Fan07]
.

\subsection{Job Scheduling}
The problem of scheduling jobs has been extensively studied. In general,
most of the schedulers implement the First Come First Served (FCFS) policy
as a simple but fair strategy for scheduling jobs. But this policy suffers
from low system utilization. The most commonly used optimization is backfill
\cite{lifka_anl/ibm_1995} 
\cite{mualem_utilization_2001}
\cite{feitelson_parallel_2004}
[Lif95, Mua95, Fei04]. Backfilling is proposed to improve the system
utilization. Backfilling by identifying free capacities allows the smaller
jobs fit those capacities to move forward and run on idle processors.

In [Yang ref is not in Zotero] 
\cite{zhou_reducing_2013}
[Yang13] and [Zhou13] , \textbf{job scheduling} as a DR strategy and
\textbf{dynamic pricing} as a grid integration program have been used to
propose \textbf{a power-aware job scheduling} approach to reduce
\textbf{electricity costs} \textit{without degrading the system utilization}. 
The novelty of the proposed job scheduling
mechanism is its ability to take \textit{the variation of 
electricity price }into consideration as a means to make
better decisions of the timing of scheduling jobs with diverse power
profiles. Experimentations on an IBM Blue Gene/P and a cluster system as
well as a case study on Argonne's 48-rack IBM Blue Gene/Q system have
demonstrated the effectiveness of this scheduling approach. Preliminary
results show a \textbf{23{\%}} reduction in electricity cost of HPC systems.

A grid computing infrastructure with large amount of computations normally
contains parallel machines (supercomputers cluster) as main computational
resources 
\cite{foster_anatomy_2001} [Fos01]
. Incoming jobs to Grid's local resources are scheduled by
local scheduling system. Local scheduling system for parallel machines
typically use batch queued space-sharing and its variants as scheduling
policies. Most current local schedulers use backfilling strategies with FCFS
queue-priority order as policy for parallel job scheduling. In the US,
supercomputer centers are connected via grid computing infrastructures such
as TeraGrid, Open Science Grid. Grid computing's protocols, interfaces, and
standards can facilitate the execution of DR strategies, as a result grid
computing may increase the interest level and/or the impact level of DR
strategies.

There are many use cases in grid computing environment that require QoS
guarantees in terms of guaranteed response time, including time-critical
tasks that must meet a deadline, which would be impossible without a start
time guarantee. Furthermore providing time guarantee enable the job to be
coordinated with other activities, essential for co-allocation and workflows
applications. Advance reservation is a guarantee for the availability of a
certain amount of resources to users and applications at specific times in
the future 
\cite{foster_distributed_1999} [Fos99]. Advance reservation feature requires local scheduling
systems to support a reservation capability beside batch queued policy for
local and normal jobs. In load migration, we encounter the need to deliver
resources at specific times in order to accept jobs from other HPC centers
to respond to their demand enforced by electricity grid. This requirement
can be achieved by advance reservations 
\cite{foster_distributed_1999}
[Fos99]. Modern resource management
and scheduling systems such as Sun Grid Engine, PBS, OpenPBS, Torque, Maui,
and Moab support backfilling and advance reservation capabilities.

By using \textit{advance reservation capabilities }of schedulers 
(within local resource managers) of HPC centers, we
facilitate \textit{the execution of load migration strategy }between 
HPC centers (e.g., in terms of automation); as a result
we increase the interest level and to some extent the impact level of load
migration strategies.


\subsection{Load Migration}

In order to balance the electrical grid,
\cite{chiu_electric_2012}
[Chiu12] proposes a low-cost
\textbf{geographic load migration} to match electricity supply. In addition,
authors present a real grid balancing problem experienced in the Pacific
Northwest. They propose a symbiotic relationship between data centers and
electrical grid operators by showing that \textbf{mutual cost benefits }can
be accessible.

\subsection{Thermal Management}
Thermal and cooling metrics are becoming important metrics in scheduling and
resource management of HPC centers. Runtime cooling strategies are mostly
job-placement-centric. These techniques either aim to place incoming
computationally intensive jobs in a thermal-aware manner on servers with
lower temperatures or attempt to reactively migrate/load-balance jobs from
high temperature servers to servers with lower temperatures.
\textbf{\textit{T* }} 

\cite{kaushik_t*:_2012}
[Kau12]
 takes a data-centric thermal- and
energy-management approach and does proactive, thermal-aware file placement
which allows cooling energy costs savings without performance trade-offs. T*
is cognizant of the uneven thermal-profile of the servers, differences in
their thermal-reliability-driven load thresholds, and differences in the
data-semantics, i.e., computation job rates, sizes, and evolution life
spans, of the big data placed in the cluster.

In this paper, we assume that the grid is a given constant as a fundamental
property. But, grid integration solutions may take into consideration that
it isn't a given as electrical grid infrastructures will evolve in the
future 
\cite{he_architecture_2008}
[He08]
. Thus, changes in the grid could make grid integration more or
less difficult.


In 
\cite{aikema_electrical_2011}
[Aik11] , authors explored the potential for HPC centers to adapt to
dynamic electrical prices, variation in carbon intensity within an
electrical grid, or availability of local renewables. Through simulations
experiments on workloads from the Parallel Workloads Archive alongside
real-world pricing data, they demonstrate potential savings on the cost of
electricity ranging typically between 10-50{\%}. Nonetheless, adaptation to
the variation in the electrical grid carbon intensity was not as successful,
but adaptation to the availability of local renewables showed potential to
significantly increase their use.
