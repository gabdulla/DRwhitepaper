

@inproceedings{bertran_accurate_2010,
	title = {Accurate energy accounting for shared virtualized environments using {PMC-based} power modeling techniques},
	doi = {10.1109/GRID.2010.5697889},
	abstract = {Virtualized infrastructure providers demand new methods to increase the accuracy of the accounting models used to charge their customers. Future data centers will be composed of many-core systems that will host a large number of virtual machines ({VMs)} each. While resource utilization accounting can be achieved with existing system tools, energy accounting is a complex task when per-{VM} granularity is the goal. In this paper, we propose a methodology that brings new opportunities to energy accounting by adding an unprecedented degree of accuracy on the per-{VM} measurements. We present a system -which leverages {CPU} and memory power models based in performance monitoring counters ({PMCs)-} to perform energy accounting in virtualized systems. The contribution of this paper is twofold. First, we show that {PMC-based} power modeling methods are still valid on virtualized environments. And second, we introduce a novel methodology for accounting of energy consumption in virtualized systems. In overall, the results for an Intel® Core™ 2 Duo show errors in energy estimations below the 5\%. Such approach brings flexibility to the chargeback models used by service and infrastructure providers. For instance, we show that {VMs} executed during the same amount of time, present more than 20\% differences in energy consumption even only taking into account the consumption of the {CPU} and the memory.},
	booktitle = {2010 11th {IEEE/ACM} International Conference on Grid Computing ({GRID)}},
	author = {Bertran, R. and Becerra, Y. and Carrera, D. and Beltran, V. and Gonzalez Tallada, M. and Martorell, X. and Torres, J. and Ayguade, E.},
	year = {2010},
	keywords = {Accuracy, Energy accounting, Energy consumption, Estimation, Hardware, {PMC} based power modeling techniques, Performance Counters, Power Modeling, Power demand, Radiation detectors, {VM}, Virtual machining, accurate energy accounting, computer centres, core systems, data centers, memory power models, power aware computing, shared virtualized environments, virtual machines, virtualization, virtualized infrastructure},
	pages = {1--8}
},

@inproceedings{foster_distributed_1999,
	title = {A distributed resource management architecture that supports advance reservations and co-allocation},
	doi = {10.1109/IWQOS.1999.766475},
	abstract = {The realization of end-to-end quality of service ({QoS)} guarantees in emerging network-based applications requires mechanisms that support first dynamic discovery and then advance or immediate reservation of resources that will often be heterogeneous in type and implementation and independently controlled and administered. We propose the Globus Architecture for Reservation and Allocation ({GARA)} to address these four issues. {GARA} treats both reservations and computational elements such as processes, network flows, and memory blocks as first-class entities, allowing them to be created, monitored, and managed independently and uniformly. It simplifies management of heterogeneous resource types by defining uniform mechanisms for computers, networks, disk, memory, and other resources. Layering on these standard mechanisms, {GARA} enables the construction of application-level co-reservation and co-allocation libraries that applications can use to dynamically assemble collections of resources, guided by both application {QoS} requirements and the local administration policy of individual resources. We describe a prototype {GARA} implementation that supports three different resource type-parallel computers, individual {CPU} under control of the dynamic soft real-time scheduler, and integrated services networks, and provide performance results that quantify the costs of our techniques},
	booktitle = {1999 Seventh International Workshop on Quality of Service, 1999. {IWQoS} '99},
	author = {Foster, I. and Kesselman, C. and Lee, C. and Lindell, B. and Nahrstedt, K. and Roy, A.},
	year = {1999},
	keywords = {Application software, Assembly, {CPU} control, Computer networks, Computerized monitoring, Globus Architecture for Reservation and Allocation, Libraries, Memory management, {QoS} guarantees, Quality of service, Resource management, advance reservations, application-level co-reservation, co-allocation, computer architecture, computer network management, distributed resource management architecture, dynamic discovery, dynamic soft real-time scheduler, heterogeneous resource types, integrated services networks, local administration policy, management, network flows, performance, performance evaluation, scheduling, telecommunication traffic, uniform mechanisms},
	pages = {27--36}
},

@incollection{zhao_advance_2007,
	series = {Lecture Notes in Computer Science},
	title = {Advance Reservation Policies for Workflows},
	copyright = {©2007 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-71034-9, 978-3-540-71035-6},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-71035-6_3},
	abstract = {Advance reservation of resources has been suggested as a means to provide a certain level of support that meets user expectations with respect to specific job start times in parallel systems. Those expectations may relate to a single job application or an application that consists of a collection of dependent jobs. In the context of Grid computing, applications consisting of dependent tasks become increasingly important, usually known as workflows. This paper focuses on the problem of planning advance reservations for individual tasks of workflow-type of applications when the user specifies a requirement only for the whole workflow application. Two policies to automate advance reservation planning for individual tasks efficiently are presented and evaluated.},
	number = {4376},
	urldate = {2013-10-03},
	booktitle = {Job Scheduling Strategies for Parallel Processing},
	publisher = {Springer Berlin Heidelberg},
	author = {Zhao, Henan and Sakellariou, Rizos},
	editor = {Frachtenberg, Eitan and Schwiegelshohn, Uwe},
	month = jan,
	year = {2007},
	keywords = {Algorithm Analysis and Problem Complexity, Computation by Abstract Devices, Logic Design, Operating Systems, Processor Architectures, Programming Techniques},
	pages = {47--67}
},

@inproceedings{dhiman_analysis_2008,
	address = {Berkeley, {CA}, {USA}},
	series = {{HotPower'08}},
	title = {Analysis of dynamic voltage scaling for system level energy management},
	url = {http://dl.acm.org/citation.cfm?id=1855610.1855619},
	abstract = {In this paper we show that in modern computing systems, {DVFS} gives much more limited energy savings with relatively high performance overhead as compared to running workloads at high speed and then transitioning into low power state. The primary reasons for this are recent advancements in platform and {CPU} architectures such as sophisticated memory subsystem design, and more efficient low power state support. We justify our analysis with measurements on a state of the art system using benchmarks ranging from very {CPU} intensive to memory intensive workloads.},
	urldate = {2013-09-24},
	booktitle = {Proceedings of the 2008 conference on Power aware computing and systems},
	publisher = {{USENIX} Association},
	author = {Dhiman, Gaurav and Pusukuri, Kishore Kumar and Rosing, Tajana},
	year = {2008},
	pages = {9–9}
},

@inproceedings{varma_control-theoretic_2003,
	address = {New York, {NY}, {USA}},
	series = {{CASES} '03},
	title = {A control-theoretic approach to dynamic voltage scheduling},
	isbn = {1-58113-676-5},
	url = {http://doi.acm.org/10.1145/951710.951744},
	doi = {10.1145/951710.951744},
	abstract = {The development of energy-conscious embedded and/or mobile systems exposes a trade-off between energy consumption and system performance. Recent microprocessors have incorporated dynamic voltage scaling as a tool that system software can use to explore this trade-off. Developing appropriate heuristics to control this feature is a non-trivial venture; as has been shown in the past, voltage-scaling heuristics that closely track perceived performance requirements do not save much energy, while those that save the most energy tend to do so at the expense of performance resulting in poor response time, for example. We note that the task of dynamically scaling processor speed and voltage to meet changing performance requirements resembles a classical control-systems problem, and so we apply a bit of control theory to the task in order to define a new voltage-scaling algorithm. We find that, using our {nqPID} (not quite {PID)} algorithm, one can improve upon the current best-of-class heuristic Pering's {AVGN} algorithm, based on Govil's {AGED} {AVERAGES} algorithm and Weiser's {PAST} algorithm in both energy consumption and performance. The study is execution-based, not-trace-based; the voltage-scaling heuristics were integrated into an embedded operating system running on a Motorola M-{CORE} processor model. The applications studied are all members of the {MediaBench} benchmark suite.},
	urldate = {2013-09-23},
	booktitle = {Proceedings of the 2003 international conference on Compilers, architecture and synthesis for embedded systems},
	publisher = {{ACM}},
	author = {Varma, Ankush and Ganesh, Brinda and Sen, Mainak and Choudhury, Suchismita Roy and Srinivasan, Lakshmi and Jacob, Bruce},
	year = {2003},
	keywords = {{PID}, dynamic voltage scaling, low-power, {nqPID}},
	pages = {255–266}
},

@inproceedings{burd_energy_1995,
	title = {Energy efficient {CMOS} microprocessor design},
	volume = {1},
	doi = {10.1109/HICSS.1995.375385},
	abstract = {Reduction of power dissipation in microprocessor design is becoming a key design constraint. This is motivated not only by portable electronics, in which battery weight and size is critical, but by heat dissipation issues in larger desktop and parallel machines as well. By identifying the major modes of computation of these processors and by proposing figures of merit for each of these modes, a power analysis methodology is developed. It allows the energy efficiency of various architectures to be quantified, and provides techniques for either individually optimizing or trading off throughput and energy consumption. The methodology is then used to qualify three important design principles for energy-efficient microprocessor design},
	booktitle = {Proceedings of the Twenty-Eighth Hawaii International Conference on System Sciences, 1995},
	author = {Burd, {T.D.} and Brodersen, {R.W.}},
	year = {1995},
	keywords = {Application software, Batteries, {CMOS} digital integrated circuits, {CMOS} logic circuits, Capacitance, Delay, Design methodology, Energy consumption, Microprocessors, Semiconductor device modeling, battery size, battery weight, computation modes, computer architecture, computer architectures, cooling, design principles, desktop computers, energy conservation, energy efficiency, energy efficiency quantification, energy efficient {CMOS} microprocessor design, figures of merit, heat dissipation, integrated circuit modelling, microprocessor chips, parallel machines, portable electronics, power analysis methodology, power dissipation, throughput},
	pages = {288--297 vol.1}
},

@inproceedings{he_architecture_2008,
	address = {Atlanta, Georgia, {USA}},
	title = {An Architecture for Local Energy Generation, Distribution, and Sharing},
	abstract = {The United States electricity grid faces significant
problems resulting from fundamental design principles that limit
its ability to handle the key energy challenges of the 21st century.
We propose an innovative electric power architecture, rooted in
lessons learned from the Internet and microgrids, which addresses
these problems while interfacing gracefully into the current grid to
allow for non-disruptive incremental adoption. Such a system,
which we term a {“LoCal”} grid, is controlled by intelligent power
switches ({IPS)}, and can consist of loads, energy sources, and
energy storage. The desired result of the proposed architecture is
to produce a grid network designed for distributed renewable
energy, prevalent energy storage, and stable autonomous systems.
We will describe organizing principles of such a system that
ensure well-behaved operation, such as requirements for
communication and energy transfer protocols, regulation and
control schemes, and market-based rules of operation.},
	booktitle = {{IEEE} Energy2030 Conference Proceedings},
	author = {He, Mike M. and Reutzel, Evan M. and Jiang, Xiaofan and Katz, Y. H. and S, Seth R. and Culler, David E.},
	month = nov,
	year = {2008}
},

@misc{_data_????,
	title = {Data Centers and Distributed Renewables: Two Peas in a {POD}},
	shorttitle = {Data Centers and Distributed Renewables},
	url = {http://blog.rmi.org/blog_2013_07_25_data_centers_and_distributed_renewables},
	abstract = {The Internet and mobile and broadband networks are here to stay. How can we make sure that the {ICT} sector uses clean, green energy, and uses it as efficiently as possible?},
	urldate = {2013-08-02},
	keywords = {electricity, microgrids}
},

@article{torriti_demand_2010,
	title = {Demand response experience in Europe: Policies, programmes and implementation},
	volume = {35},
	issn = {0360-5442},
	shorttitle = {Demand Response Resources: the {US} and International Experience Demand Response Resources: the {US} and International Experience},
	url = {http://www.sciencedirect.com/science/article/pii/S0360544209002060},
	doi = {10.1016/j.energy.2009.05.021},
	abstract = {Over the last few years, load growth, increases in intermittent generation, declining technology costs and increasing recognition of the importance of customer behaviour in energy markets have brought about a change in the focus of Demand Response ({DR)} in Europe. The long standing programmes involving large industries, through interruptible tariffs and time of day pricing, have been increasingly complemented by programmes aimed at commercial and residential customer groups. Developments in {DR} vary substantially across Europe reflecting national conditions and triggered by different sets of policies, programmes and implementation schemes. This paper examines experiences within European countries as well as at European Union ({EU)} level, with the aim of understanding which factors have facilitated or impeded advances in {DR.} It describes initiatives, studies and policies of various European countries, with in-depth case studies of the {UK}, Italy and Spain. It is concluded that while business programmes, technical and economic potentials vary across Europe, there are common reasons as to why coordinated {DR} policies have been slow to emerge. This is because of the limited knowledge on {DR} energy saving capacities; high cost estimates for {DR} technologies and infrastructures; and policies focused on creating the conditions for liberalising the {EU} energy markets.},
	number = {4},
	urldate = {2013-07-31},
	journal = {Energy},
	author = {Torriti, Jacopo and Hassan, Mohamed G. and Leach, Matthew},
	month = apr,
	year = {2010},
	keywords = {European Union, Market liberalisation, Smart meter, demand response},
	pages = {1575--1583}
},

@article{chiu_electric_2012,
	title = {Electric grid balancing through lowcost workload migration},
	volume = {40},
	issn = {0163-5999},
	url = {http://doi.acm.org/10.1145/2425248.2425259},
	doi = {10.1145/2425248.2425259},
	abstract = {Energy production must continuously match demand on the electric grid. A deficiency can lead to service disruptions, and a surplus can place tremendous stress on grid components, potentially causing major blackouts. To manage this balance, grid operators must increase or lower power generation, with only a few minutes to react. The grid balancing problem has also impeded the pace of integrating bountiful renewable resources (e.g., wind), whose generation is intermittent. An emerging plan to mitigate this problem is demand response, i.e., for grid operators to alter the electricity usage behavior of the masses through real-time price signals. But due to prohibitively high infrastructure costs and societal-scale adoption, tangible demand response mechanisms have so far been elusive. We believe that altering the usage patterns of a multitude of data centers can be a tangible, albeit initial, step towards affecting demand response. Growing in both density and size, today's data center designs are shaped by the increasing awareness of energy costs and carbon footprint. We posit that shifting computational workloads (and thus, demand) across geographic regions to match electricity supply may help balance the grid. In this paper we will first present a real grid balancing problem experienced in the Pacfic Northwest. We then propose a symbiotic relationship between data centers and grid operators by showing that mutual cost benefits can be accessible. Finally, we argue for a low cost workload migration mechanism, and pose overarching challenges in designing this framework.},
	number = {3},
	urldate = {2013-07-26},
	journal = {{SIGMETRICS} Perform. Eval. Rev.},
	author = {Chiu, David and Stewart, Christopher and {McManus}, Bart},
	month = jan,
	year = {2012},
	keywords = {data centers, demand response, smart grid},
	pages = {48–52}
},

@article{parvania_demand_2010,
	title = {Demand Response Scheduling by Stochastic {SCUC}},
	volume = {1},
	issn = {1949-3053},
	doi = {10.1109/TSG.2010.2046430},
	abstract = {Considerable developments in the real-time telemetry of demand-side systems allow independent system operators ({ISOs)} to use reserves provided by demand response ({DR)} in ancillary service markets. Currently, many {ISOs} have designed programs to utilize the reserve provided by {DR} in electricity markets. This paper presents a stochastic model to schedule reserves provided by {DR} in the wholesale electricity markets. Demand-side reserve is supplied by demand response providers ({DRPs)}, which have the responsibility of aggregating and managing customer responses. A mixed-integer representation of reserve provided by {DRPs} and its associated cost function are used in the proposed stochastic model. The proposed stochastic model is formulated as a two-stage stochastic mixed-integer programming ({SMIP)} problem. The first-stage involves network-constrained unit commitment in the base case and the second-stage investigates security assurance in system scenarios. The proposed model would schedule reserves provided by {DRPs} and determine commitment states of generating units and their scheduled energy and spinning reserves in the scheduling horizon. The proposed approach is applied to two test systems to illustrate the benefits of implementing demand-side reserve in electricity markets.},
	number = {1},
	journal = {{IEEE} Transactions on Smart Grid},
	author = {Parvania, M. and Fotuhi-Firuzabad, M.},
	year = {2010},
	keywords = {Ancillary service markets, {ISO}, data center, demand response, demand response scheduling, demand side management, demand-side systems, electricity markets, independent system operators, integer programming, mixed-integer programming, mixed-integer representation, power generation scheduling, power markets, real-time telemetry, security cost, stochastic {SCUC}, stochastic security-constrained unit commitment, uncertainty},
	pages = {89--98}
},

@inproceedings{liu_data_2013,
	address = {New York, {NY}, {USA}},
	series = {{SIGMETRICS} '13},
	title = {Data center demand response: avoiding the coincident peak via workload shifting and local generation},
	isbn = {978-1-4503-1900-3},
	shorttitle = {Data center demand response},
	url = {http://doi.acm.org/10.1145/2465529.2465740},
	doi = {10.1145/2465529.2465740},
	abstract = {Demand response is a crucial aspect of the future smart grid. It has the potential to provide significant peak demand reduction and to ease the incorporation of renewable energy into the grid. Data centers' participation in demand response is becoming increasingly important given the high and increasing energy consumption and the flexibility in demand management in data centers compared to conventional industrial facilities. In this extended abstract we briefly describe recent work in our full paper on two demand response schemes to reduce a data center's peak loads and energy expenditure: workload shifting and the use of local power generations. In our full paper, we conduct a detailed characterization study of coincident peak data over two decades from Fort Collins Utilities, Colorado and then develop two algorithms for data centers by combining workload scheduling and local power generation to avoid the coincident peak and reduce the energy expenditure. The first algorithm optimizes the expected cost and the second one provides a good worst-case guarantee for any coincident peak pattern. We evaluate these algorithms via numerical simulations based on real world traces from production systems. The results show that using workload shifting in combination with local generation can provide significant cost savings (up to 40\% in the Fort Collins Utilities' case) compared to either alone.},
	urldate = {2013-07-31},
	publisher = {{ACM}},
	author = {Liu, Zhenhua and Wierman, Adam and Chen, Yuan and Razon, Benjamin and Chen, Niangjun},
	year = {2013},
	keywords = {coincident peak pricing, data center, demand response, online algorithm, workload shifting},
	pages = {341–342}
},

@inproceedings{albadi_demand_2007,
	title = {Demand Response in Electricity Markets: An Overview},
	shorttitle = {Demand Response in Electricity Markets},
	doi = {10.1109/PES.2007.385728},
	abstract = {This paper presents an overview of demand response ({DR)} in electricity market. The definition and a classification of demand response will be presented. Different potential benefits as well as cost components of demand response will be presented. The most common indices used for demand response evaluation are highlighted. Moreover, some utilities experiences with different demand response programs will be presented.},
	author = {Albadi, M. H. and El-Saadany, {E.F.}},
	year = {2007},
	keywords = {Costs, Distributed power generation, Electricity supply industry, Energy consumption, Load management, Potential well, Price-based programs, Pricing, Reliability, Thermostats, Timing, demand response, demand side management, electricity markets, incentive based programs, market based programs, power markets, price based programs, price elasticity, real time pricing},
	pages = {1--5}
},

@article{borenstein_dynamic_2002,
	title = {Dynamic Pricing, Advanced Metering, and Demand Response in Electricity Markets},
	url = {http://escholarship.org/uc/item/11w8d6m4},
	abstract = {In this monograph, we present an overview and analysis of the possible approaches to bringing an active demand side into electricity markets. In section I, we describe the ways in which economic incentives can be introduced on the demand side. We discuss the fundamental economics of establishing these incentives and the economic loss from systems that lack demand-side participation, and we analyze the effect of these incentives on the efficiency and competitiveness of the market. In section {II}, we move from the fundamentals to specific issues of implementing time-varying prices. We begin by describing illustrative Realtime Pricing and Critical Peak Pricing tariffs that are in use today. We then address the actual development of dynamic retail prices. In section {III}, we examine the ways in which customers respond to time-varying and dynamic prices. We discuss both the potential responses that are envisioned by those who study optimization of power use and the actual responses that have taken place in pilot and long-term programs. We conclude in section {IV} by advocating much wider use of dynamic retail pricing, under which prices faced by end-use customers can be adjusted frequently and on short notice to reflect changes in wholesale prices and the supply/demand balance.},
	urldate = {2013-07-31},
	author = {Borenstein, Severin and Jaske, Michael and Rosenfeld, Arthur},
	month = oct,
	year = {2002}
},

@article{palensky_demand_2011,
	title = {Demand Side Management: Demand Response, Intelligent Energy Systems, and Smart Loads},
	volume = {7},
	issn = {1551-3203},
	shorttitle = {Demand Side Management},
	doi = {10.1109/TII.2011.2158841},
	abstract = {Energy management means to optimize one of the most complex and important technical creations that we know: the energy system. While there is plenty of experience in optimizing energy generation and distribution, it is the demand side that receives increasing attention by research and industry. Demand Side Management ({DSM)} is a portfolio of measures to improve the energy system at the side of consumption. It ranges from improving energy efficiency by using better materials, over smart energy tariffs with incentives for certain consumption patterns, up to sophisticated real-time control of distributed energy resources. This paper gives an overview and a taxonomy for {DSM}, analyzes the various types of {DSM}, and gives an outlook on the latest demonstration projects in this domain.},
	number = {3},
	journal = {{IEEE} Transactions on Industrial Informatics},
	author = {Palensky, P. and Dietrich, D.},
	year = {2011},
	keywords = {Automation, Building automation, {IEC} 61850, {IEC} standards, Load management, Load modeling, Power generation, Pricing, Smart grids, Spinning, demand response, demand side management, demand side management ({DSM)}, distributed energy resources, electric power generation, energy distribution, energy efficiency, energy generation, energy management, energy management systems, intelligent energy systems, peak shaving, power distribution, smart loads, sophisticated real-time control},
	pages = {381--388}
},

@article{spees_demand_2007,
	title = {Demand Response and Electricity Market Efficiency},
	volume = {20},
	issn = {1040-6190},
	url = {http://www.sciencedirect.com/science/article/pii/S1040619007000188},
	doi = {10.1016/j.tej.2007.01.006},
	abstract = {Customer response is a neglected way of solving electricity industry problems. Historically, providers have focused on supply, assuming that consumers are unwilling or unable to modify their consumption. Contrary to these expectations, customers respond to higher prices that they expect to continue by purchasing more efficient appliances and taking other efficiency measures, a review of published studies indicates.},
	number = {3},
	urldate = {2013-07-31},
	journal = {The Electricity Journal},
	author = {Spees, Kathleen and Lave, Lester B.},
	month = apr,
	year = {2007},
	pages = {69--85}
},

@article{rahimi_demand_2010,
	title = {Demand Response as a Market Resource Under the Smart Grid Paradigm},
	volume = {1},
	issn = {1949-3053},
	doi = {10.1109/TSG.2010.2045906},
	abstract = {Demand response ({DR)}, distributed generation ({DG)}, and distributed energy storage ({DES)} are important ingredients of the emerging smart grid paradigm. For ease of reference we refer to these resources collectively as distributed energy resources ({DER).} Although much of the {DER} emerging under smart grid are targeted at the distribution level, {DER}, and more specifically {DR} resources, are considered important elements for reliable and economic operation of the transmission system and the wholesale markets. In fact, viewed from transmission and wholesale operations, sometimes the term ??virtual power plant?? is used to refer to these resources. In the context of energy and ancillary service markets facilitated by the independent system operators ({ISOs)/regional} transmission organizations ({RTOs)}, the market products {DER/DR} can offer may include energy, ancillary services, and/or capacity, depending on the {ISO/RTO} market design and applicable operational standards. In this paper we first explore the main industry drivers of smart grid and the different facets of {DER} under the smart grid paradigm. We then concentrate on {DR} and summarize the existing and evolving programs at different {ISOs/RTOs} and the product markets they can participate in. We conclude by addressing some of the challenges and potential solutions for implementation of {DR} under smart grid and market paradigms.},
	number = {1},
	journal = {{IEEE} Transactions on Smart Grid},
	author = {Rahimi, F. and Ipakchi, A.},
	year = {2010},
	keywords = {Ancillary service markets, demand response, demand response ({DR)}, demand side management, distributed energy resources ({DER)}, distributed energy storage, distributed generation, energy markets, energy storage, independent system operators, market resource, power markets, regional transmission organizations, smart grid, smart grid paradigm, smart power grids},
	pages = {82--88}
},

@article{albadi_summary_2008,
	title = {A summary of demand response in electricity markets},
	volume = {78},
	issn = {0378-7796},
	url = {http://www.sciencedirect.com/science/article/pii/S0378779608001272},
	doi = {10.1016/j.epsr.2008.04.002},
	abstract = {This paper presents a summary of Demand Response ({DR)} in deregulated electricity markets. The definition and the classification of {DR} as well as potential benefits and associated cost components are presented. In addition, the most common indices used for {DR} measurement and evaluation are highlighted, and some utilities’ experiences with different demand response programs are discussed. Finally, the effect of demand response in electricity prices is highlighted using a simulated case study.},
	number = {11},
	urldate = {2013-07-31},
	journal = {Electric Power Systems Research},
	author = {Albadi, {M.H.} and El-Saadany, {E.F.}},
	month = nov,
	year = {2008},
	keywords = {demand response, electricity markets, price elasticity, real time pricing},
	pages = {1989--1996}
},

@article{sharma_balance_2005,
	title = {Balance of Power: Dynamic Thermal Management for Internet Data Centers},
	volume = {9},
	issn = {1089-7801},
	shorttitle = {Balance of Power},
	url = {http://dx.doi.org/10.1109/MIC.2005.10},
	doi = {10.1109/MIC.2005.10},
	abstract = {The advent of Internet-based applications and their resulting multitier distributed architecture has changed the focus of design for large-scale Internet computing. Internet server applications execute in a horizontally scalable topology across hundreds or thousands of commodity servers in an Internet data center. Increasing scale and power density have a significant impact on the data center's thermal properties. Effective thermal management is essential to the robustness of mission-critical applications. Internet service architectures can address multisystem resource management and thermal management at the granularity of data centers. This article presents a framework for thermal-load balancing by applying load monitoring and dynamic workload placement to manage the thermal distribution within a data center. The results demonstrate that dynamic thermal management based on asymmetric workload placement can promote uniform temperature distribution that reduces local hot spots, quickly responds to thermal emergencies, reduces energy consumption costs, reduces initial cooling system capital costs and improves equipment reliability.},
	number = {1},
	urldate = {2013-07-26},
	journal = {{IEEE} Internet Computing},
	author = {Sharma, Ratnesh K. and Bash, Cullen E. and Patel, Chandrakant D. and Friedrich, Richard J. and Chase, Jeffrey S.},
	month = jan,
	year = {2005},
	keywords = {Internet data center, dynamic thermal management, row-wise and regional thermal management, thermal policies, thermal-load balancing},
	pages = {42–49}
},

@article{son_sla-based_2013,
	title = {An {SLA-based} cloud computing that facilitates resource allocation in the distributed data centers of a cloud provider},
	volume = {64},
	issn = {0920-8542},
	url = {http://dx.doi.org/10.1007/s11227-012-0861-z},
	doi = {10.1007/s11227-012-0861-z},
	abstract = {The number of cloud service users has increased worldwide, and cloud service providers have been deploying and operating data centers to serve the globally distributed cloud users. The resource capacity of a data center is limited, so distributing the load to global data centers will be effective in providing stable services. Another issue in cloud computing is the need for providers to guarantee the service level agreements ({SLAs)} established with consumers. Whereas various load balancing algorithms have been developed, it is necessary to avoid {SLA} violations (e.g., service response time) when a cloud provider allocates the load to data centers geographically distributed across the world. Considering load balancing and guaranteed {SLA}, therefore, this paper proposes an {SLA-based} cloud computing framework to facilitate resource allocation that takes into account the workload and geographical location of distributed data centers. The contributions of this paper include: (1) the design of a cloud computing framework that includes an automated {SLA} negotiation mechanism and a workload- and location-aware resource allocation scheme ({WLARA)}, and (2) the implementation of an agent-based cloud testbed of the proposed framework. Using the testbed, experiments were conducted to compare the proposed schemes with related approaches. Empirical results show that the proposed {WLARA} performs better than other related approaches (e.g., round robin, greedy, and manual allocation) in terms of {SLA} violations and the provider's profits. We also show that using the automated {SLA} negotiation mechanism supports providers in earning higher profits.},
	number = {2},
	urldate = {2013-07-26},
	journal = {J. Supercomput.},
	author = {Son, Seokho and Jung, Gihun and Jun, Sung Chan},
	month = may,
	year = {2013},
	keywords = {Cloud computing, Distributed data centers, Resource allocation, {SLA} management, {SLA} negotiation, {VM} placement},
	pages = {606–637}
},

@inproceedings{bash_cool_2007,
	address = {Berkeley, {CA}, {USA}},
	series = {{ATC'07}},
	title = {Cool job allocation: measuring the power savings of placing jobs at cooling-efficient locations in the data center},
	isbn = {999-8888-77-6},
	shorttitle = {Cool job allocation},
	url = {http://dl.acm.org/citation.cfm?id=1364385.1364414},
	abstract = {Data center costs for computer power and cooling are staggering. Because certain physical locations inside the data center are more efficient to cool than others, this suggests that allocating heavy computational workloads onto those servers that are in more efficient places might bring substantial savings. This simple idea raises two critical research questions that we address: (1) How should one measure and rank the cooling efficiency of different places in a data center? (2) How substantial is the savings? We performed a set of experiments in a thermally isolated portion of a real data center, and validated that the potential savings is substantial and therefore warrants further work in this area to exploit the savings opportunity.},
	urldate = {2013-07-26},
	publisher = {{USENIX} Association},
	author = {Bash, Cullen and Forman, George},
	year = {2007},
	pages = {29:1–29:6}
},

@inproceedings{thusoo_data_2010,
	address = {New York, {NY}, {USA}},
	series = {{SIGMOD} '10},
	title = {Data warehousing and analytics infrastructure at facebook},
	isbn = {978-1-4503-0032-2},
	url = {http://doi.acm.org/10.1145/1807167.1807278},
	doi = {10.1145/1807167.1807278},
	abstract = {Scalable analysis on large data sets has been core to the functions of a number of teams at Facebook - both engineering and non-engineering. Apart from ad hoc analysis of data and creation of business intelligence dashboards by analysts across the company, a number of Facebook's site features are also based on analyzing large data sets. These features range from simple reporting applications like Insights for the Facebook Advertisers, to more advanced kinds such as friend recommendations. In order to support this diversity of use cases on the ever increasing amount of data, a flexible infrastructure that scales up in a cost effective manner, is critical. We have leveraged, authored and contributed to a number of open source technologies in order to address these requirements at Facebook. These include Scribe, Hadoop and Hive which together form the cornerstones of the log collection, storage and analytics infrastructure at Facebook. In this paper we will present how these systems have come together and enabled us to implement a data warehouse that stores more than {15PB} of data ({2.5PB} after compression) and loads more than {60TB} of new data ({10TB} after compression) every day. We discuss the motivations behind our design choices, the capabilities of this solution, the challenges that we face in day today operations and future capabilities and improvements that we are working on.},
	urldate = {2013-07-26},
	publisher = {{ACM}},
	author = {Thusoo, Ashish and Shao, Zheng and Anthony, Suresh and Borthakur, Dhruba and Jain, Namit and Sen Sarma, Joydeep and Murthy, Raghotham and Liu, Hao},
	year = {2010},
	keywords = {analytics, data discovery, data warehouse, distributed file system, distributed systems, facebook, hadoop, hive, log aggregation, map-reduce, resource sharing, scalability, scribe},
	pages = {1013–1020}
}


@inproceedings{aikema_electrical_2011,
	title = {Electrical cost savings and clean energy usage potential for {HPC} workloads},
	doi = {10.1109/ISSST.2011.5936911},
	abstract = {Data centres containing high-performance computing ({HPC)} clusters may be able to coordinate with the operation of wind farms for mutual benefit. Large data centres consume megawatts of power, typically accounting for a majority of life cycle carbon emissions and a significant portion of the total cost of ownership. We ran simulations to explore the potential for data centres to adapt to dynamic electrical prices, variation in carbon intensity within an electrical grid, or the availability of local renewables. Using workloads from the Parallel Workloads Archive alongside real-world pricing data, we demonstrate potential savings on the cost of electricity ranging typically between 10-50\%. Adaptation to the variation in the electrical grid carbon intensity was not as successful, but adaptation to the availability of local renewables showed potential to significantly increase their use. In one example the fraction of power obtained from a local wind installation increased by 10-80\%.},
	booktitle = {2011 {IEEE} International Symposium on Sustainable Systems and Technology ({ISSST)}},
	author = {Aikema, D. and Simmonds, R.},
	year = {2011},
	keywords = {Adaptive Scheduling, Availability, Carbon, Electric potential, Energy consumption, Environmental Economics, {HPC} workloads, High performance computing, Power demand, Simulation, Wind power, Wind power generation, Wind turbines, clean energy usage potential, electrical cost savings, electricity, high-performance computing clusters, power markets, wind farms},
	pages = {1--6}
},

@inproceedings{burd_energy_1995,
	title = {Energy efficient {CMOS} microprocessor design},
	volume = {1},
	doi = {10.1109/HICSS.1995.375385},
	abstract = {Reduction of power dissipation in microprocessor design is becoming a key design constraint. This is motivated not only by portable electronics, in which battery weight and size is critical, but by heat dissipation issues in larger desktop and parallel machines as well. By identifying the major modes of computation of these processors and by proposing figures of merit for each of these modes, a power analysis methodology is developed. It allows the energy efficiency of various architectures to be quantified, and provides techniques for either individually optimizing or trading off throughput and energy consumption. The methodology is then used to qualify three important design principles for energy-efficient microprocessor design},
	booktitle = {Proceedings of the Twenty-Eighth Hawaii International Conference on System Sciences, 1995},
	author = {Burd, {T.D.} and Brodersen, {R.W.}},
	year = {1995},
	keywords = {Application software, Batteries, {CMOS} digital integrated circuits, {CMOS} logic circuits, Capacitance, Delay, Design methodology, Energy consumption, Microprocessors, Semiconductor device modeling, battery size, battery weight, computation modes, computer architecture, computer architectures, cooling, design principles, desktop computers, energy conservation, energy efficiency, energy efficiency quantification, energy efficient {CMOS} microprocessor design, figures of merit, heat dissipation, integrated circuit modelling, microprocessor chips, parallel machines, portable electronics, power analysis methodology, power dissipation, throughput},
	pages = {288--297 vol.1}
},


@article{parvania_demand_2010,
	title = {Demand Response Scheduling by Stochastic {SCUC}},
	volume = {1},
	issn = {1949-3053},
	doi = {10.1109/TSG.2010.2046430},
	abstract = {Considerable developments in the real-time telemetry of demand-side systems allow independent system operators ({ISOs)} to use reserves provided by demand response ({DR)} in ancillary service markets. Currently, many {ISOs} have designed programs to utilize the reserve provided by {DR} in electricity markets. This paper presents a stochastic model to schedule reserves provided by {DR} in the wholesale electricity markets. Demand-side reserve is supplied by demand response providers ({DRPs)}, which have the responsibility of aggregating and managing customer responses. A mixed-integer representation of reserve provided by {DRPs} and its associated cost function are used in the proposed stochastic model. The proposed stochastic model is formulated as a two-stage stochastic mixed-integer programming ({SMIP)} problem. The first-stage involves network-constrained unit commitment in the base case and the second-stage investigates security assurance in system scenarios. The proposed model would schedule reserves provided by {DRPs} and determine commitment states of generating units and their scheduled energy and spinning reserves in the scheduling horizon. The proposed approach is applied to two test systems to illustrate the benefits of implementing demand-side reserve in electricity markets.},
	number = {1},
	journal = {{IEEE} Transactions on Smart Grid},
	author = {Parvania, M. and Fotuhi-Firuzabad, M.},
	year = {2010},
	keywords = {Ancillary service markets, {ISO}, data center, demand response, demand response scheduling, demand side management, demand-side systems, electricity markets, independent system operators, integer programming, mixed-integer programming, mixed-integer representation, power generation scheduling, power markets, real-time telemetry, security cost, stochastic {SCUC}, stochastic security-constrained unit commitment, uncertainty},
	pages = {89--98}
},

@inproceedings{albadi_demand_2007,
	title = {Demand Response in Electricity Markets: An Overview},
	shorttitle = {Demand Response in Electricity Markets},
	doi = {10.1109/PES.2007.385728},
	abstract = {This paper presents an overview of demand response ({DR)} in electricity market. The definition and a classification of demand response will be presented. Different potential benefits as well as cost components of demand response will be presented. The most common indices used for demand response evaluation are highlighted. Moreover, some utilities experiences with different demand response programs will be presented.},
	author = {Albadi, M. H. and El-Saadany, {E.F.}},
	year = {2007},
	keywords = {Costs, Distributed power generation, Electricity supply industry, Energy consumption, Load management, Potential well, Price-based programs, Pricing, Reliability, Thermostats, Timing, demand response, demand side management, electricity markets, incentive based programs, market based programs, power markets, price based programs, price elasticity, real time pricing},
	pages = {1--5}
},

@article{borenstein_dynamic_2002,
	title = {Dynamic Pricing, Advanced Metering, and Demand Response in Electricity Markets},
	url = {http://escholarship.org/uc/item/11w8d6m4},
	abstract = {In this monograph, we present an overview and analysis of the possible approaches to bringing an active demand side into electricity markets. In section I, we describe the ways in which economic incentives can be introduced on the demand side. We discuss the fundamental economics of establishing these incentives and the economic loss from systems that lack demand-side participation, and we analyze the effect of these incentives on the efficiency and competitiveness of the market. In section {II}, we move from the fundamentals to specific issues of implementing time-varying prices. We begin by describing illustrative Realtime Pricing and Critical Peak Pricing tariffs that are in use today. We then address the actual development of dynamic retail prices. In section {III}, we examine the ways in which customers respond to time-varying and dynamic prices. We discuss both the potential responses that are envisioned by those who study optimization of power use and the actual responses that have taken place in pilot and long-term programs. We conclude in section {IV} by advocating much wider use of dynamic retail pricing, under which prices faced by end-use customers can be adjusted frequently and on short notice to reflect changes in wholesale prices and the supply/demand balance.},
	urldate = {2013-07-31},
	author = {Borenstein, Severin and Jaske, Michael and Rosenfeld, Arthur},
	month = oct,
	year = {2002}
},

@article{palensky_demand_2011,
	title = {Demand Side Management: Demand Response, Intelligent Energy Systems, and Smart Loads},
	volume = {7},
	issn = {1551-3203},
	shorttitle = {Demand Side Management},
	doi = {10.1109/TII.2011.2158841},
	abstract = {Energy management means to optimize one of the most complex and important technical creations that we know: the energy system. While there is plenty of experience in optimizing energy generation and distribution, it is the demand side that receives increasing attention by research and industry. Demand Side Management ({DSM)} is a portfolio of measures to improve the energy system at the side of consumption. It ranges from improving energy efficiency by using better materials, over smart energy tariffs with incentives for certain consumption patterns, up to sophisticated real-time control of distributed energy resources. This paper gives an overview and a taxonomy for {DSM}, analyzes the various types of {DSM}, and gives an outlook on the latest demonstration projects in this domain.},
	number = {3},
	journal = {{IEEE} Transactions on Industrial Informatics},
	author = {Palensky, P. and Dietrich, D.},
	year = {2011},
	keywords = {Automation, Building automation, {IEC} 61850, {IEC} standards, Load management, Load modeling, Power generation, Pricing, Smart grids, Spinning, demand response, demand side management, demand side management ({DSM)}, distributed energy resources, electric power generation, energy distribution, energy efficiency, energy generation, energy management, energy management systems, intelligent energy systems, peak shaving, power distribution, smart loads, sophisticated real-time control},
	pages = {381--388}
},

@article{spees_demand_2007,
	title = {Demand Response and Electricity Market Efficiency},
	volume = {20},
	issn = {1040-6190},
	url = {http://www.sciencedirect.com/science/article/pii/S1040619007000188},
	doi = {10.1016/j.tej.2007.01.006},
	abstract = {Customer response is a neglected way of solving electricity industry problems. Historically, providers have focused on supply, assuming that consumers are unwilling or unable to modify their consumption. Contrary to these expectations, customers respond to higher prices that they expect to continue by purchasing more efficient appliances and taking other efficiency measures, a review of published studies indicates.},
	number = {3},
	urldate = {2013-07-31},
	journal = {The Electricity Journal},
	author = {Spees, Kathleen and Lave, Lester B.},
	month = apr,
	year = {2007},
	pages = {69--85}
},

@article{rahimi_demand_2010,
	title = {Demand Response as a Market Resource Under the Smart Grid Paradigm},
	volume = {1},
	issn = {1949-3053},
	doi = {10.1109/TSG.2010.2045906},
	abstract = {Demand response ({DR)}, distributed generation ({DG)}, and distributed energy storage ({DES)} are important ingredients of the emerging smart grid paradigm. For ease of reference we refer to these resources collectively as distributed energy resources ({DER).} Although much of the {DER} emerging under smart grid are targeted at the distribution level, {DER}, and more specifically {DR} resources, are considered important elements for reliable and economic operation of the transmission system and the wholesale markets. In fact, viewed from transmission and wholesale operations, sometimes the term ??virtual power plant?? is used to refer to these resources. In the context of energy and ancillary service markets facilitated by the independent system operators ({ISOs)/regional} transmission organizations ({RTOs)}, the market products {DER/DR} can offer may include energy, ancillary services, and/or capacity, depending on the {ISO/RTO} market design and applicable operational standards. In this paper we first explore the main industry drivers of smart grid and the different facets of {DER} under the smart grid paradigm. We then concentrate on {DR} and summarize the existing and evolving programs at different {ISOs/RTOs} and the product markets they can participate in. We conclude by addressing some of the challenges and potential solutions for implementation of {DR} under smart grid and market paradigms.},
	number = {1},
	journal = {{IEEE} Transactions on Smart Grid},
	author = {Rahimi, F. and Ipakchi, A.},
	year = {2010},
	keywords = {Ancillary service markets, demand response, demand response ({DR)}, demand side management, distributed energy resources ({DER)}, distributed energy storage, distributed generation, energy markets, energy storage, independent system operators, market resource, power markets, regional transmission organizations, smart grid, smart grid paradigm, smart power grids},
	pages = {82--88}
}



@article{stadler_power_2008,
	title = {Power grid balancing of energy systems with high renewable energy penetration by demand response},
	volume = {16},
	issn = {0957-1787},
	url = {http://www.sciencedirect.com/science/article/pii/S0957178707000732},
	doi = {10.1016/j.jup.2007.11.006},
	abstract = {It is generally accepted that the integration of intermittent energy resources like wind energy and photovoltaics into an electricity system cannot exceed a limit of around 20\% or 25\%, see, e.g. [{EWEA}, 2005. Large-scale integration of wind energy in the European power supply: analysis, issues and recommendations. The European Wind Energy Association]. However, the decoupling of electricity generation and consumption cannot be implemented only by use of electricity storage. In the end, electricity is converted into many different energy services – quite often into thermal energy – which is better suited for storage. This article presents the results of investigations which studied the potential of those demand response activities for Germany. The investigations are based on both modelling of thermal storage devices and laboratory tests.},
	number = {2},
	urldate = {2013-10-23},
	journal = {Utilities Policy},
	author = {Stadler, Ingo},
	month = jun,
	year = {2008},
	keywords = {Renewable energies, Thermal energy storage, demand response},
	pages = {90--98}
},

@article{zhou_reducing_2013,
	title = {Reducing Energy Costs for {IBM} Blue {Gene/P} via Power-Aware Job Scheduling},
	url = {http://www.cs.huji.ac.il/~feit/parsched/jsspp13/zhou.pdf},
	abstract = {Energy expense is becoming increasingly dominant in the
operating costs of high-performance computing ({HPC)} systems. At the
same time, electricity prices vary significantly at different times of the
day. Furthermore, job power profiles also differ greatly, especially on {HPC}
systems. In this paper, we propose a smart, power-aware job scheduling
approach for {HPC} systems based on variable energy prices and job pow-
er profiles. In particular, we propose a 0-1 knapsack model and demon-
strate its flexibility and effectiveness for scheduling jobs, with the goal
of reducing energy cost and not degrading system utilization. We design
scheduling strategies for Blue {Gene/P}, a typical partition-based system.
Experiments with both synthetic data and real job traces from produc-
tion systems show that our power-aware job scheduling approach can
reduce the energy cost significantly, up to 25\%, with only slight impact
on system utilization.},
	urldate = {2013-10-18},
journal = { },
	author = {Zhou, Zhou and Lan, Zhiling and Tang, Wei and Desai, Narayan}
},

@article{jimenez_energy-aware_2011,
	title = {Energy-Aware Accounting and Billing in Large-Scale Computing Facilities},
	volume = {31},
	issn = {0272-1732},
	doi = {10.1109/MM.2011.35},
	abstract = {Proposals have focused on reducing energy requirements for large-scale computing facilities ({LSCFs)}, but little research has addressed the need for energy-usage-based accounting. Energy-aware accounting and billing benefits {LSCF} owners and users. This article makes a case for accurate cost accounting and billing, which accounts for user-specific energy usage, and identifies the hardware- and software-level changes necessary to support energy-aware accounting.},
	number = {3},
	journal = {{IEEE} Micro},
	author = {Jimenez, V. and Gioiosa, R. and Cazorla, {F.J.} and Valero, M. and Kursun, E and Isci, C. and Buyuktosunoglu, A. and Bose, P.},
	year = {2011},
	keywords = {Energy consumption, Energy-aware systems, Hardware, Power demand, Power management, Resource management, Virtual machining, computer systems organization, cooling, cost accounting, emerging technologies, energy conservation, energy requirements, energy-aware accounting, energy-aware billing, hardware/software interfaces, invoicing, large-scale computing facilities, servers},
	pages = {60--71}
},

@inproceedings{feitelson_parallel_2004,
	title = {Parallel Job Scheduling - A Status Report},
	abstract = {Scheduling parallel jobs has been a popular research topic for many years. A couple of surveys have been written on this topic in the context of parallel supercomputers [17, 20]. The purpose of the present paper is to update},
	booktitle = {In Lecture Notes in Computer Science},
	publisher = {Springer-Verlag},
	author = {Feitelson, Dror G. and Schwiegelshohn, Uwe and Rudolph, Larry},
	year = {2004},
	pages = {1–16}
},

@inproceedings{raicu_falkon:_2007,
	address = {New York, {NY}, {USA}},
	series = {{SC} '07},
	title = {Falkon: a Fast and Light-weight {tasK} {executiON} framework},
	isbn = {978-1-59593-764-3},
	shorttitle = {Falkon},
	url = {http://doi.acm.org/10.1145/1362622.1362680},
	doi = {10.1145/1362622.1362680},
	abstract = {To enable the rapid execution of many tasks on compute clusters, we have developed Falkon, a Fast and Light-weight {tasK} {executiON} framework. Falkon integrates (1) multi-level scheduling to separate resource acquisition (via, e.g., requests to batch schedulers) from task dispatch, and (2) a streamlined dispatcher. Falkon's integration of multi-level scheduling and streamlined dispatchers delivers performance not provided by any other system. We describe Falkon architecture and implementation, and present performance results for both microbenchmarks and applications. Microbenchmarks show that Falkon throughput (487 tasks/sec) and scalability (to 54,000 executors and 2,000,000 tasks processed in just 112 minutes) are one to two orders of magnitude better than other systems used in production Grids. Large-scale astronomy and medical applications executed under Falkon by the Swift parallel programming system achieve up to 90\% reduction in end-to-end run time, relative to versions that execute tasks via separate scheduler submissions.},
	urldate = {2013-10-03},
	booktitle = {Proceedings of the 2007 {ACM/IEEE} conference on Supercomputing},
	publisher = {{ACM}},
	author = {Raicu, Ioan and Zhao, Yong and Dumitrescu, Catalin and Foster, Ian and Wilde, Mike},
	year = {2007},
	keywords = {dynamic resource provisioning, grid computing, parallel programming, scheduling},
	pages = {43:1–43:12}
},

@inproceedings{fan_power_2007,
	title = {Power Provisioning for a Warehouse-sized Computer},
	booktitle = {In Proceedings of {ISCA}},
	author = {Fan, Xiaobo and Weber, Wolf-dietrich and Barroso, Luiz André},
	year = {2007}
},

@inproceedings{kim_power_2007,
	title = {Power Aware Scheduling of Bag-of-Tasks Applications with Deadline Constraints on {DVS-enabled} Clusters},
	doi = {10.1109/CCGRID.2007.85},
	abstract = {Power-aware scheduling problem has been a recent issue in cluster systems not only for operational cost due to electricity cost, but also for system reliability. As recent commodity processors support multiple operating points under various supply voltage levels, Dynamic Voltage Scaling ({DVS)} scheduling algorithms can reduce power consumption by controlling appropriate voltage levels. In this paper, we provide power-aware scheduling algorithms for bag-of-tasks applications with deadline constraints on {DVS-enabled} cluster systems in order to minimize power consumption as well as to meet the deadlines specified by application users. A bag-of-tasks application should finish all the sub-tasks before the deadline, so that the {DVS} scheduling scheme should consider the deadline as well. We provide the {DVS} scheduling algorithms for both time-shared and space-shared resource sharing policies. The simulation results show that the proposed algorithms reduce much power consumption compared to static voltage schemes.},
	booktitle = {Seventh {IEEE} International Symposium on Cluster Computing and the Grid, 2007. {CCGRID} 2007},
	author = {Kim, Kyong Hoon and Buyya, R. and Kim, Jong},
	year = {2007},
	keywords = {Costs, {DVS-enabled} cluster system, Energy consumption, Quality of service, Reliability, Resource allocation, Scheduling Algorithm, Temperature, Voltage control, bag-of-task application, deadline constraint, dynamic voltage scaling, energy management, power aware computing, power aware scheduling, power consumption, power system management, scheduling, space-shared resource sharing, system reliability, time-shared resource sharing, time-sharing programs, workstation clusters},
	pages = {541--548}
},

@inproceedings{von_laszewski_power-aware_2009,
	title = {Power-aware scheduling of virtual machines in {DVFS-enabled} clusters},
	doi = {10.1109/CLUSTR.2009.5289182},
	abstract = {With the advent of Cloud computing, large-scale virtualized compute and data centers are becoming common in the computing industry. These distributed systems leverage commodity server hardware in mass quantity, similar in theory to many of the fastest Supercomputers in existence today. However these systems can consume a cities worth of power just to run idle, and require equally massive cooling systems to keep the servers within normal operating temperatures. This produces {CO2} emissions and significantly contributes to the growing environmental issue of Global Warming. Green computing, a new trend for high-end computing, attempts to alleviate this problem by delivering both high performance and reduced power consumption, effectively maximizing total system efficiency. This paper focuses on scheduling virtual machines in a compute cluster to reduce power consumption via the technique of Dynamic Voltage Frequency Scaling ({DVFS).} Specifically, we present the design and implementation of an efficient scheduling algorithm to allocate virtual machines in a {DVFS-enabled} cluster by dynamically scaling the supplied voltages. The algorithm is studied via simulation and implementation in a multi-core cluster. Test results and performance discussion justify the design and implementation of the scheduling algorithm.},
	booktitle = {{IEEE} International Conference on Cluster Computing and Workshops, 2009. {CLUSTER} '09},
	author = {von Laszewski, G. and Wang, Lizhe and Younge, {A.J.} and He, Xi},
	year = {2009},
	keywords = {Algorithm design and analysis, Cloud computing, Cluster Computing, Dynamic Voltage and Frequency Scaling, Energy consumption, High performance computing, Job shop scheduling, Large-scale systems, Scheduling Algorithm, Virtual machining, computer cluster, dynamic voltage frequency scaling, dynamic voltage scaling, global warming, green computing, high-end computing, microprocessor chips, multicore cluster, power aware computing, power-aware scheduling, processor scheduling, scheduling, supervisory programs, virtual machine, virtual machines, workstation clusters},
	pages = {1--10}
},

@inproceedings{azevedo_profile-based_2002,
	address = {Washington, {DC}, {USA}},
	series = {{DATE} '02},
	title = {Profile-Based Dynamic Voltage Scheduling Using Program Checkpoints},
	isbn = {0-7695-1471-5},
	url = {http://dl.acm.org/citation.cfm?id=882452.874373},
	abstract = {Dynamic voltage scaling ({DVS)} is a known effectivemechanism for reducing {CPU} energy consumption withoutsignificant performance degradation. While a lot of workhas been done on inter-task scheduling algorithms to {implementDVS} under operating system control, new researchchallenges exist in intra-task {DVS} techniques under softwareand compiler control. In this paper we introduce anovel intra-task {DVS} technique under compiler control usingprogram checkpoints. Checkpoints are generated atcompile time and indicate places in the code where the processorspeed and voltage should be re-calculated. Check-pointsalso carry user-defined time constraints. Our techniquehandles multiple intra-task performance deadlinesand modulates power consumption according to a run-timepower budget. We experimented with two heuristics for adjustingthe clock frequency and voltage. For the particularbenchmark studied, one heuristic yielded 63\% more energysavings than the other. With the best of the heuristics we designed,our technique resulted in 82\% energy savings overthe execution of the program without employing {DVS.}},
	urldate = {2013-09-23},
	booktitle = {Proceedings of the conference on Design, automation and test in Europe},
	publisher = {{IEEE} Computer Society},
	author = {Azevedo, A. and Issenin, I. and Cornea, R. and Gupta, R. and Dutt, N. and Veidenbaum, A. and Nicolau, A.},
	year = {2002},
	pages = {168–}
},

@article{hong_power_1999,
	title = {Power optimization of variable-voltage core-based systems},
	volume = {18},
	issn = {0278-0070},
	doi = {10.1109/43.811318},
	abstract = {The growing class of portable systems, such as personal computing and communication devices, has resulted in a new set of system design requirements, mainly characterized by dominant importance of power minimization and design reuse. The energy efficiency of systems-on-a-chip ({SOC)} could be much improved if one were to vary the supply voltage dynamically at run time. We developed the design methodology for the low-power core-based real-time {SOC} based on dynamically variable voltage hardware. The key challenge is to develop effective scheduling techniques that treat voltage as a variable to be determined, in addition to the conventional task scheduling and allocation. Our synthesis technique also addresses the selection of the processor core and the determination of the instruction and data cache size and configuration so as to fully exploit dynamically variable voltage hardware, which results in significantly lower power consumption for a set of target applications than existing techniques. The highlight of the proposed approach is the nonpreemptive scheduling heuristic, which results in solutions very close to optimal ones for many test cases. The effectiveness of the approach is demonstrated on a variety of modern industrial strength multimedia and communication applications},
	number = {12},
	journal = {{IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Hong, I. and Kirovski, D. and Qu, Gang and Potkonjak, M. and Srivastava, {M.B.}},
	year = {1999},
	keywords = {Design methodology, Energy consumption, Hardware, Job shop scheduling, Portable computers, System-on-a-chip, Testing, Voltage, data cache size, design reuse, dynamically variable voltage hardware, embedded systems, energy efficiency, high level synthesis, high-level synthesis, instruction size, integrated circuit design, low-power core-based real-time {SOC}, low-power electronics, multimedia applications, nonpreemptive scheduling heuristic, power minimization, processor core, processor scheduling, scheduling, scheduling techniques, supply voltage, system design requirements, systems-on-a-chip, variable-voltage core-based systems},
	pages = {1702--1714}
},

@inproceedings{chase_managing_2001,
	title = {Managing Energy and Server Resources in Hosting Centers},
	abstract = {Interact hosting centers serve multiple service sites from a common hardware base. This paper presents the design and implementation of an architecture for resource management in a hosting center op-erating system, with an emphasis on energy as a driving resource management issue for large server clusters. The goals are to provi-sion server resources for co-hosted services in a way that automati-cally adapts to offered load, improve the energy efficiency of server dusters by dynamically resizing the active server set, and respond to power supply disruptions or thermal events by degrading service in accordance with negotiated Service Level Agreements ({SLAs).} Our system is based on an economic approach to managing shared server resources, in which services \&quot;bid \&quot; for resources as a func-tion of delivered performance. The system continuously moni-tors load and plans resource allotments by estimating the value of their effects on service performance. A greedy resource allocation algorithm adjusts resource prices to balance supply and demand, allocating resources to their most efficient use. A reconfigurable server switching infrastructure directs request traffic to the servers assigned to each service. Experimental results from a prototype confirm that the system adapts to offered load and resource avail-ability, and can reduce server energy usage by 29 \% or more for a typical Web workload. 1.},
	booktitle = {In Proceedings of the 18th {ACM} Symposium on Operating System Principles ({SOSP}},
	author = {Chase, Jeffrey S. and Anderson, Darrell C. and Thakar, Prachi N. and Vahdat, Amin M.},
	year = {2001},
	pages = {103–116}
},

@inproceedings{rao_minimizing_2010,
	title = {Minimizing electricity cost: Optimization of distributed internet data centers in a multi-electricity-market environment},
	shorttitle = {Minimizing electricity cost},
	abstract = {{Abstract—The} study of Cyber-Physical System ({CPS)} has been an active area of research. Internet Data Center ({IDC)} is an important emerging Cyber-Physical System. As the demand on Internet services drastically increases in recent years, the power used by {IDCs} has been skyrocketing. While most existing research focuses on reducing power consumptions of {IDCs}, the power management problem for minimizing the total electricity cost has been overlooked. This is an important problem faced by service providers, especially in the current multi-electricity market, where the price of electricity may exhibit time and location diversities. Further, for these service providers, guaranteeing quality of service (i.e. service level objectives-{SLO)} such as service delay guarantees to the end users is of paramount importance. This paper studies the problem of minimizing the total electricity cost under multiple electricity markets environment while guaranteeing quality of service geared to the location diversity and time diversity of electricity price. We model the problem as a constrained mixed-integer programming and propose an efficient solution method. Extensive evaluations based on reallife electricity price data for multiple {IDC} locations illustrate the efficiency and efficacy of our approach. I.},
	booktitle = {In Proc. of {INFOCOM}},
	author = {Rao, Lei and Liu, Xue and Liu, Wenyu},
	year = {2010}
},

@book{liu_greening_????,
	title = {Greening Geographical Load Balancing},
	abstract = {Energy expenditure has become a significant fraction of data center operating costs. Recently, “geographical load balancing” has been suggested to reduce energy cost by exploiting the electricity price differences across regions. However, this reduction of cost can paradoxically increase total energy use. This paper explores whether the geographical diversity of Internet-scale systems can additionally be used to provide environmental gains. Specifically, we explore whether geographical load balancing can encourage use of“green”renewable energy and reduce use of “brown ” fossil fuel energy. We make two contributions. First, we derive two distributed algorithms for achieving optimal geographical load balancing. Second, we show that if electricity is dynamically priced in proportion to the instantaneous fraction of the total energy that is brown, then geographical load balancing provides significant reductions in brown energy use. However, the benefits depend strongly on the degree to which systems accept dynamic energy pricing and the form of pricing used.},
	author = {Liu, Zhenhua and Lin, Minghong and Wierman, Adam and Low, Steven H. and Andrew, Lachlan L. H.}
},

@inproceedings{zhou_impact_2012,
	title = {Impact of demand response contracts on load forecasting in a smart grid environment},
	doi = {10.1109/PESGM.2012.6345079},
	abstract = {Load forecasting is highly important for power system operation and planning. Demand response, as a valuable feature in smart grid, is growing dramatically as an effective demand management method. However, traditional load forecasting tools have limitations to reflect demand response customer behaviors into load predictions. The energy consumption by demand response customers is mostly guided by their signed contracts. Therefore, existing demand response contracts are reviewed in this study for both wholesale and retail markets. An illustrative example is provided to explore the impact of these contracts on load forecasting. A concept of proactive load forecasting considering contract types is then proposed and discussed for forecasting loads in a smart grid environment.},
	booktitle = {2012 {IEEE} Power and Energy Society General Meeting},
	author = {Zhou, Qun and Guan, Wei and Sun, Wei},
	year = {2012},
	keywords = {Energy consumption, Forecasting, Load management, Pricing, Smart grids, consumer behaviour, contract types, contracts, customer behaviors, demand response, demand response contract, demand response customer behaviors, effective demand management method, electricity, electricity prices, load forecasting, load predictions, power markets, power system management, power system operation, power system planning, proactive load forecasting, retail market, smart grid, smart grid environment, smart power grids, traditional load forecasting tools, wholesale market},
	pages = {1--4}
},

@inproceedings{krioukov_napsac:_2010,
	address = {New York, {NY}, {USA}},
	series = {Green Networking '10},
	title = {{NapSAC:} design and implementation of a power-proportional web cluster},
	isbn = {978-1-4503-0196-1},
	shorttitle = {{NapSAC}},
	url = {http://doi.acm.org/10.1145/1851290.1851294},
	doi = {10.1145/1851290.1851294},
	abstract = {Energy consumption is a major and costly problem in data centers. A large fraction of this energy goes to powering idle machines that are not doing any useful work. We identify two causes of this inefficiency: low server utilization and a lack of power-proportionality. To address this problem we present a design for an power-proportional cluster consisting of a power-aware cluster manager and a set of heterogeneous machines. Our design makes use of currently available energy-efficient hardware, mechanisms for transitioning in and out of low-power sleep states, and dynamic provisioning and scheduling to continually adjust to workload and minimize power consumption. With our design we are able to reduce energy consumption while maintaining acceptable response times for a web service workload based on Wikipedia. With our dynamic provisioning algorithms we demonstrate via simulation a 63\% savings in power usage in a typically provisioned datacenter where all machines are left on and awake at all times. Our results show that we are able to achieve close to 90\% of the savings a theoretically optimal provisioning scheme would achieve. We have also built a prototype cluster which runs Wikipedia to demonstrate the use of our design in a real environment.},
	urldate = {2013-08-23},
	booktitle = {Proceedings of the first {ACM} {SIGCOMM} workshop on Green networking},
	publisher = {{ACM}},
	author = {Krioukov, Andrew and Mohan, Prashanth and Alspaugh, Sara and Keys, Laura and Culler, David and Katz, Randy H.},
	year = {2010},
	keywords = {Power management, cluster, data center, energy, heterogenous hardware, power proportional, web application, web server},
	pages = {15–22}
},

@inproceedings{goiri_greenslot:_2011,
	address = {New York, {NY}, {USA}},
	series = {{SC} '11},
	title = {{GreenSlot:} scheduling energy consumption in green datacenters},
	isbn = {978-1-4503-0771-0},
	shorttitle = {{GreenSlot}},
	url = {http://doi.acm.org/10.1145/2063384.2063411},
	doi = {10.1145/2063384.2063411},
	abstract = {In this paper, we propose {GreenSlot}, a parallel batch job scheduler for a datacenter powered by a photovoltaic solar array and the electrical grid (as a backup). {GreenSlot} predicts the amount of solar energy that will be available in the near future, and schedules the workload to maximize the green energy consumption while meeting the jobs' deadlines. If grid energy must be used to avoid deadline violations, the scheduler selects times when it is cheap. Our results for production scientific workloads demonstrate that Green-Slot can increase green energy consumption by up to 117\% and decrease energy cost by up to 39\%, compared to a conventional scheduler. Based on these positive results, we conclude that green datacenters and green-energy-aware scheduling can have a significant role in building a more sustainable {IT} ecosystem.},
	urldate = {2013-07-22},
	booktitle = {High Performance Computing, Networking, Storage and Analysis ({SC)}, 2011 International Conference for},
	publisher = {{ACM}},
	author = {Goiri, Íñigo and Beauchea, Ryan and Le, Kien and Nguyen, Thu D. and Haque, Md. E. and Guitart, Jordi and Torres, Jordi and Bianchini, Ricardo},
	year = {2011},
	keywords = {datacenters, energy-aware job scheduling, green energy},
	pages = {20:1–20:11}
},

@inproceedings{bodenstein_low-energy_2011,
	address = {New York, {NY}, {USA}},
	series = {{ACE} '11},
	title = {Low-energy automated scheduling of computing resources},
	isbn = {978-1-4503-0734-5},
	url = {http://doi.acm.org/10.1145/1998561.1998566},
	doi = {10.1145/1998561.1998566},
	abstract = {The cost of electricity for datacenters is a substantial operational cost that can and should be managed, not only for saving energy, but also due to the ecologic commitment inherent to power consumption. This work proposes, formalizes and numerically evaluates {LEAS}, a low-energy scheduling model, for clearing scheduling markets, based on the maximization of welfare, subject to utility-level dependant energy costs. We promote energy-efficient policies in management of datacenters, to enhance the efficiency of modernized datacenters. We focus specifically on linear power models, and the implications of the inherent fixed costs related to energy consumption of modern datacenters. We rigorously test the model by running multiple simulation scenarios derived from real workload traces, and evaluate the results using common statistical methods. We conclude with positive results and implications for long-term sustainable management of modern datacenters.},
	urldate = {2013-07-26},
	publisher = {{ACM}},
	author = {Bodenstein, Christian and Hedwig, Markus and Neumann, Dirk},
	year = {2011},
	keywords = {datacenters, decision support system, green it, scheduling},
	pages = {11–18}
},

@inproceedings{sharma_building_2008,
	address = {New York, {NY}, {USA}},
	series = {{COMPUTE} '08},
	title = {On building next generation data centers: energy flow in the information technology stack},
	isbn = {978-1-59593-950-0},
	shorttitle = {On building next generation data centers},
	url = {http://doi.acm.org/10.1145/1341771.1341780},
	doi = {10.1145/1341771.1341780},
	abstract = {The demand for data center solutions with lower total cost of ownership and lower complexity of management is driving the creation of next generation datacenters The information technology industry is in the midst of a transformation to lower the cost of operation through consolidation and better utilization of critical data center resources. Successful consolidation necessitates increasing utilization of capital intensive "always-on" data center infrastructure, and reducing the recurring cost of power. A need exists, therefore for an end to end methodology that can be used to design and manage dense data centers and determine the cost of operating a data center. The chip core to the cooling tower model must capture the power levels and thermo-fluids behavior of chips, systems, aggregation of systems in racks, rows of racks, room flow distribution, air conditioning equipment, hydronics, vapor compression systems, pumps and heat exchangers. Earlier work has outlined the foundation for creation of a "smart" data center through use of flexible cooling resources and a distributed sensing and control system that can provision the cooling resources based on the need. This paper shows a common platform which serves as an evaluation and basis for policy based control engine for such a "smart" data center with much broader reach -- from chip core to the cooling tower. In this paper, we propose a data center solution, which has three components: Cooling, Power and Compute. These three components collectively improve efficiency and manageability of the data center by supporting greater compaction, flexible building blocks that can be dynamically configured, dynamic optimization, better monitoring and visualization, and policy-based control. Coefficient of performance ({COP)} of the ensemble is defined that represents an overall measure of the efficiency of performance of energy flow during the operation of a data center.},
	urldate = {2013-07-26},
	publisher = {{ACM}},
	author = {Sharma, Ratnesh K. and Shih, Rocky and Bash, Cullen and Patel, Chandrakant and Varghese, Philip and Mekanapurath, Mohandas and Velayudhan, Sankaragopal and {Kumar,V}, Manu},
	year = {2008},
	keywords = {data center management, energy efficiency, smart cooling, smart data center, sustainability},
	pages = {8:1–8:7}
},

@article{tang_energy-efficient_2008,
	title = {Energy-Efficient Thermal-Aware Task Scheduling for Homogeneous High-Performance Computing Data Centers: A Cyber-Physical Approach},
	volume = {19},
	issn = {1045-9219},
	shorttitle = {Energy-Efficient Thermal-Aware Task Scheduling for Homogeneous High-Performance Computing Data Centers},
	url = {http://dx.doi.org/10.1109/TPDS.2008.111},
	doi = {10.1109/TPDS.2008.111},
	abstract = {High Performance Computing data centers have been rapidly growing, both in number and in size. Thermal management of data centers can address dominant problems associated with cooling such as the recirculation of hot air from the equipment outlets to their inlets, and the appearance of hot spots. In this paper, we are looking into assigning the incoming tasks to machines of a data center in such a way so as to affect the heat recirculation and make cooling more efficient. Using a low complexity linear heat recirculation model, we formulate the problem of minimizing the peak inlet temperature within a data center through task assignment, consequently leading to minimal cooling power consumption. We also provide two methods to solve the formulation, one that uses a genetic algorithm and the other that uses sequential quadratic programming. We show through formalization that minimizing the peak inlet temperature allows for the lowest cooling power needs. Results from a simulated, small-scale data center show that solving the formulation leads to an inlet temperature distribution that is 2 {°C} to 5 {°C} lower compared to other approaches, and achieves about 20\%-30\% cooling energy savings at moderate data center utilization rates. Moreover, our algorithms consistently outperform {MinHR}, a recirculation-reducing placement algorithm in the literature.},
	number = {11},
	urldate = {2013-07-26},
	journal = {{IEEE} Trans. Parallel Distrib. Syst.},
	author = {Tang, Qinghui and Gupta, Sandeep Kumar S. and Varsamopoulos, Georgios},
	month = nov,
	year = {2008},
	keywords = {Measurement, Modeling techniques, evaluation, modeling, simulation of multiple-processor systems},
	pages = {1458–1472}
},

@article{williams_integrating_2013,
	title = {Integrating renewable energy using a smart distribution system: Potential of self-regulating demand response},
	volume = {52},
	issn = {0960-1481},
	shorttitle = {Integrating renewable energy using a smart distribution system},
	url = {http://www.sciencedirect.com/science/article/pii/S0960148112006507},
	doi = {10.1016/j.renene.2012.10.013},
	abstract = {A self-regulating distribution system simulation platform is presented for a smart-grid with Distributed Energy Resource ({DER)} wind power injection in which load flow fluctuations are controlled via self-regulating air-source heat pump ({HP)} cycling. The grid power injection fluctuations are mitigated by bus-level {HP} control, while ensuring compliance to both consumer comfort constraints and distribution grid load flow requirements.

The effects of applying a number of different bus-level {HP} control algorithms are evaluated. The results show that using building thermal mass in conjunction with simple control strategies can effectively accommodate large fluctuations associated with high penetration of wind energy. The number of {HPs} in each distribution phase significantly affects the load flow characteristics and the ability of the bus-level control to smooth the distribution grid regulator power.

The bus-level control improves power and voltage ramping rates, reduces wind power injection fluctuations, and also reduces the energy reserve requirements.},
	urldate = {2013-07-31},
	journal = {Renewable Energy},
	author = {Williams, Trevor and Wang, Dan and Crawford, Curran and Djilali, Ned},
	month = apr,
	year = {2013},
	keywords = {Distributed heat pumps, Distribution load flow analysis, {GridLAB-D}, Wind power, demand response},
	pages = {46--56}
},

@patent{belluomini_-demand_2013,
	title = {{ON-DEMAND} {STORAGE} {SYSTEM} {ENERGY} {SAVINGS}},
	url = {http://www.freepatentsonline.com/y2013/0013941.html},
	abstract = {Embodiments of the invention relate to dynamic power management of storage volumes and disk arrays in a storage subsystem to mitigate loss of performance resulting from the power management. The volumes and arrays are prioritized, and in real-time power is selectively reduced in response to both the prioritization and an energy savings goal. A feedback loop is provided to dynamically measure associated power gain based upon a lowering of power consumption, and device selection may be adjusted based upon received feedback.},
	nationality = {United States},
	assignee = {{INTERNATIONAL} {BUSINESS} {MACHINES} {CORPORATION} (Armonk, {NY}, {US)}},
	number = {20130013941},
	urldate = {2013-07-31},
	author = {Belluomini, Wendy A. and Chambliss, David D. and Glider, Joseph S. and Pucha, Himabindu and Zhang, Rui},
	month = jan,
	year = {2013}
},

@inproceedings{moore_making_2005,
	address = {Berkeley, {CA}, {USA}},
	series = {{ATEC} '05},
	title = {Making scheduling "cool": temperature-aware workload placement in data centers},
	shorttitle = {Making scheduling "cool"},
	url = {http://dl.acm.org/citation.cfm?id=1247360.1247365},
	abstract = {Trends towards consolidation and higher-density computing configurations make the problem of heat management one of the critical challenges in emerging data centers. Conventional approaches to addressing this problem have focused at the facilities level to develop new cooling technologies or optimize the delivery of cooling. In contrast to these approaches, our paper explores an alternate dimension to address this problem, namely a systems-level solution to control the heat generation through temperature-aware workload placement. We first examine a theoretic thermodynamic formulation that uses information about steady state hot spots and cold spots in the data center and develop real-world scheduling algorithms. Based on the insights from these results, we develop an alternate approach. Our new approach leverages the non-intuitive observation that the source of cooling inefficiencies can often be in locations spatially uncorrelated with its manifested consequences; this enables additional energy savings. Overall, our results demonstrate up to a factor of two reduction in annual data center cooling costs over location-agnostic workload distribution, purely through software optimizations without the need for any costly capital investment.},
	urldate = {2013-07-26},
	publisher = {{USENIX} Association},
	author = {Moore, Justin and Chase, Jeff and Ranganathan, Parthasarathy and Sharma, Ratnesh},
	year = {2005},
	pages = {5–5}
},

@inproceedings{wang_opportunities_2010,
	address = {New York, {NY}, {USA}},
	series = {{FeBiD} '10},
	title = {Opportunities and challenges to unify workload, power, and cooling management in data centers},
	isbn = {978-1-4503-0077-3},
	url = {http://doi.acm.org/10.1145/1791204.1791205},
	doi = {10.1145/1791204.1791205},
	abstract = {Independent optimization for workload and power management, and active cooling control have been studied extensively to improve data center energy efficiency. Recently, proposals have started to advocate unified workload, power, and cooling management for further energy savings. In this paper, we study this problem with the objectives of both saving energy and capping power. We present the detailed models derived in our previous work from experiments on an blade enclosure system that can be representative of a data center, discuss the optimization opportunities for coordinated power and cooling management, and the challenges for controller design. We then propose a few design principles and examples for unified workload management, power minimization, and power capping. Our simulation-based evaluation shows that the controllers can cap the total power consumption while maintaining the thermal conditions and improve the overall energy efficiency. We argue that the same opportunities, challenges, and designs are also generally applicable to data center level management.},
	urldate = {2013-07-26},
	publisher = {{ACM}},
	author = {Wang, Zhikui and Tolia, Niraj and Bash, Cullen},
	year = {2010},
	pages = {1–6}
},

@article{conejo_real-time_2010,
	title = {Real-Time Demand Response Model},
	volume = {1},
	issn = {1949-3053},
	doi = {10.1109/TSG.2010.2078843},
	abstract = {This paper describes an optimization model to adjust the hourly load level of a given consumer in response to hourly electricity prices. The objective of the model is to maximize the utility of the consumer subject to a minimum daily energy-consumption level, maximum and minimum hourly load levels, and ramping limits on such load levels. Price uncertainty is modeled through robust optimization techniques. The model materializes into a simple linear programming algorithm that can be easily integrated in the Energy Management System of a household or a small business. A simple bidirectional communication device between the power supplier and the consumer enables the implementation of the proposed model. Numerical simulations illustrating the interest of the proposed model are provided.},
	number = {3},
	journal = {{IEEE} Transactions on Smart Grid},
	author = {Conejo, {A.J.} and Morales, {J.M.} and Baringo, L.},
	year = {2010},
	keywords = {Bidirectional communication, Bidirectional control, Energy consumption, Load modeling, Pricing, Real time systems, Smart grids, consumer behaviour, consumer demand, demand response, demand side management, energy management system, energy management systems, hourly prices, household, linear programming, linear programming algorithm, optimisation, optimization, power markets, power supplier, price uncertainty},
	pages = {236--242}
},

@inproceedings{le_reducing_2011,
	address = {New York, {NY}, {USA}},
	series = {{SC} '11},
	title = {Reducing electricity cost through virtual machine placement in high performance computing clouds},
	isbn = {978-1-4503-0771-0},
	url = {http://doi.acm.org/10.1145/2063384.2063413},
	doi = {10.1145/2063384.2063413},
	abstract = {In this paper, we first study the impact of load placement policies on cooling and maximum data center temperatures in cloud service providers that operate multiple geographically distributed data centers. Based on this study, we then propose dynamic load distribution policies that consider all electricity-related costs as well as transient cooling effects. Our evaluation studies the ability of different cooling strategies to handle load spikes, compares the behaviors of our dynamic cost-aware policies to cost-unaware and static policies, and explores the effects of many parameter settings. Among other interesting results, we demonstrate that (1) our policies can provide large cost savings, (2) load migration enables savings in many scenarios, and (3) all electricity-related costs must be considered at the same time for higher and consistent cost savings.},
	urldate = {2013-07-26},
	publisher = {{ACM}},
	author = {Le, Kien and Bianchini, Ricardo and Zhang, Jingru and Jaluria, Yogesh and Meng, Jiandong and Nguyen, Thu D.},
	year = {2011},
	keywords = {computing cloud, cooling, energy, multi-data-center},
	pages = {22:1–22:12}
}



@misc{_spie_????,
	title = {{SPIE} {\textbar} Proceeding {\textbar} Defect classification using machine learning},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=799343},
	urldate = {2013-11-18}
},

@book{hay_case_????,
	title = {The Case for Apportionment},
	abstract = {Apportioning the total energy consumption of a building or organisation to individual users may provide incentives to make reductions. We explore how sensor systems installed in many buildings today can be used to apportion energy consumption between users. We investigate the differences between a number of possible policies to evaluate the case for apportionment based on energy and usage data collected over the course of a year. We also study the additional possibilities offered by more fine-grained data with reference to case studies for specific shared resources, and discuss the potential and challenges for future sensor systems in this area.},
	author = {Hay, Simon and Rice, Andrew}
},

@inproceedings{hay_case_2009,
	address = {New York, {NY}, {USA}},
	series = {{BuildSys} '09},
	title = {The case for apportionment},
	isbn = {978-1-60558-824-7},
	url = {http://doi.acm.org/10.1145/1810279.1810283},
	doi = {10.1145/1810279.1810283},
	abstract = {Apportioning the total energy consumption of a building or organisation to individual users may provide incentives to make reductions. We explore how sensor systems installed in many buildings today can be used to apportion energy consumption between users. We investigate the differences between a number of possible policies to evaluate the case for apportionment based on energy and usage data collected over the course of a year. We also study the additional possibilities offered by more fine-grained data with reference to case studies for specific shared resources, and discuss the potential and challenges for future sensor systems in this area.},
	urldate = {2013-10-07},
	booktitle = {Proceedings of the First {ACM} Workshop on Embedded Sensing Systems for Energy-Efficiency in Buildings},
	publisher = {{ACM}},
	author = {Hay, Simon and Rice, Andrew},
	year = {2009},
	keywords = {energy, meter, personal},
	pages = {13–18}
},

@inproceedings{foster_anatomy_2001,
	title = {The anatomy of the grid: enabling scalable virtual organizations},
	shorttitle = {The anatomy of the grid},
	doi = {10.1109/CCGRID.2001.923162},
	abstract = {Not Available},
	booktitle = {First {IEEE/ACM} International Symposium on Cluster Computing and the Grid, 2001. Proceedings},
	author = {Foster, I.},
	year = {2001},
	keywords = {Anatomy, Application software, Collaborative software, Computer science, Distributed computing, Internet, Peer to peer computing, Problem-solving, Resource management, Space technology},
	pages = {6--7}
},

@article{mualem_utilization_2001,
	title = {Utilization, Predictability, Workloads, and User Runtime Estimates in Scheduling the {IBM} {SP2} with Backfilling},
	volume = {12},
	issn = {1045-9219},
	url = {http://dx.doi.org/10.1109/71.932708},
	doi = {10.1109/71.932708},
	abstract = {Scheduling jobs on the {IBM} {SP2} system and many other distributed-memory {MPPs} is usually done by giving each job a partition of the machine for its exclusive use. Allocating such partitions in the order in which the jobs arrive ({FCFS} scheduling) is fair and predictable, but suffers from severe fragmentation, leading to low utilization. This situation led to the development of the {EASY} scheduler which uses aggressive backfilling: Small jobs are moved ahead to fill in holes in the schedule, provided they do not delay the first job in the queue. We compare this approach with a more conservative approach in which small jobs move ahead only if they do not delay any job in the queue and show that the relative performance of the two schemes depends on the workload: For workloads typical on {SP2} systems, the aggressive approach is indeed better, but, for other workloads, both algorithms are similar. In addition, we study the sensitivity of backfilling to the accuracy of the runtime estimates provided by the users and find a very surprising result: Backfilling actually works better when users overestimate the runtime by a substantial factor.},
	number = {6},
	urldate = {2013-10-03},
	journal = {{IEEE} Trans. Parallel Distrib. Syst.},
	author = {Mu'alem, Ahuva W. and Feitelson, Dror G.},
	month = jun,
	year = {2001},
	keywords = {Parallel job scheduling, backfilling, performance metrics., runtime estimates, workload modeling},
	pages = {529–543}
},

@inproceedings{lifka_anl/ibm_1995,
	title = {The {ANL/IBM} {SP} scheduling system},
	abstract = {During the past ve years scientists discovered that modern {UNIX} workstations connected with ethernet and ber networks could provide enough computational performance to compete with the supercomputers of the day. As this concept became increasingly popular, the need for distributed queuing and scheduling systems became apparent. Systems such as {DQS} from Florida State were developed and worked very well. Today, supercomputers, such as Argonne National Laboratory's {IBM} {SP} system, can provide more {CPU} and networking speed than can be obtained from these networks of workstations. These modern supercomputers look like clusters of workstations, however, so developers felt that the scheduling systems that were previously used on clusters of workstations should still apply. After trying to apply some of these scheduling systems to Argonne's {SP} environment, it became obvious that these two computer environments have very di erent scheduling needs. Recognizing this need and realizing that no one has addressed it, I developed a new scheduling system. The approach taken in creating this system was unique in that user input and interaction were encouraged throughout the development process. Thus, ascheduler was built that actually \&quot;worked \&quot; the way the users wanted it to work.},
	booktitle = {In Job Scheduling Strategies for Parallel Processing},
	publisher = {Springer-Verlag},
	author = {Lifka, David A.},
	year = {1995},
	pages = {295–303}
},

@inproceedings{czajkowski_resource_1999,
	title = {Resource co-allocation in computational grids},
	doi = {10.1109/HPDC.1999.805301},
	abstract = {Applications designed to execute on “computational grids” frequently require the simultaneous co-allocation of multiple resources in order to meet performance requirements. For example, several computers and network elements may be required in order to achieve real-time reconstruction of experimental data, while a large numerical simulation may require simultaneous access to multiple supercomputers. Motivated by these concerns, we have developed a general resource management architecture for Grid environments, in which resource co-allocation is an integral component. We examine the co-allocation problem in detail and present mechanisms that allow an application to guide resource selection during the co-allocation process; these mechanisms address issues relating to the allocation, monitoring, control, and configuration of distributed computations. We describe the implementation of co-allocators based on these mechanisms and present the results of microbenchmark studies and large-scale application experiments that provide insights into the costs and practical utility of our techniques},
	booktitle = {The Eighth International Symposium on High Performance Distributed Computing, 1999. Proceedings},
	author = {Czajkowski, K. and Foster, I. and Kesselman, C.},
	year = {1999},
	keywords = {Application software, Computer networks, Distributed computing, Grid environments, Large-scale systems, Monitoring, Resource allocation, Resource management, computational grids, computer architecture, distributed computations, distributed processing, grid computing, microbenchmark studies, numerical simulation, performance evaluation, performance requirements, real-time data reconstruction, real-time systems, resource co-allocation, resource management architecture, supercomputers},
	pages = {219--228}
},

@inproceedings{beckman_spruce:_2006,
	title = {{SPRUCE:} A System for Supporting Urgent High-Performance Computing},
	shorttitle = {{SPRUCE}},
	abstract = {Modeling and simulation using high-performance computing are playing an increasingly important role in decision making and prediction. For time-critical emergency decision support applications, such as influenza modeling and severe weather prediction, late results may be useless. A specialized infrastructure is needed to provide computational resources quickly. This paper describes the architecture and implementation of {SPRUCE}, a system for supporting urgent computing on both traditional supercomputers and distributed computing Grids. Currently deployed on the {TeraGrid}, {SPRUCE} provides users with “right-of-way tokens ” that can be activated from a Web-based portal or Web service invocation in the event of an urgent computing need. Tokens are transferrable and can be restricted to specific resource sets and priority levels. Once a session is activated, job submissions may request elevated priority. Based on local policy, computing resources can respond, for example, by preempting active jobs or raising the job’s priority in the queue. This paper also explores the strengths and weaknesses of the {SPRUCE} architecture and token-based activation for urgent computing applications. 1},
	booktitle = {{IFIP} {WoCo9} Conference Proceedings, Arizona},
	author = {Beckman, Pete and Nadella, Suman and Trebon, Nick and Beschastnikh, Ivan},
	year = {2006}
},

@inproceedings{dhiman_vgreen:_2009,
	address = {New York, {NY}, {USA}},
	series = {{ISLPED} '09},
	title = {{vGreen:} a system for energy efficient computing in virtualized environments},
	isbn = {978-1-60558-684-7},
	shorttitle = {{vGreen}},
	url = {http://doi.acm.org/10.1145/1594233.1594292},
	doi = {10.1145/1594233.1594292},
	abstract = {In this paper, we present {vGreen}, a multi-tiered software system for energy efficient computing in virtualized environments. It comprises of novel hierarchical metrics that capture power and performance characteristics of virtual and physical machines, and policies, which use it for energy efficient virtual machine scheduling across the whole deployment. We show through real life implementation on a state of the art testbed of server machines that {vGreen} can improve both performance and system level energy savings by 20\% and 15\% across benchmarks with varying characteristics.},
	urldate = {2013-09-23},
	booktitle = {Proceedings of the 14th {ACM/IEEE} international symposium on Low power electronics and design},
	publisher = {{ACM}},
	author = {Dhiman, Gaurav and Marchetti, Giacomo and Rosing, Tajana},
	year = {2009},
	keywords = {energy, migration, virtualization, workload characterization},
	pages = {243–248}
},

@book{pinedo_scheduling_2008,
	edition = {3rd},
	title = {Scheduling - Theory, Algorithms, and Systems},
	volume = {3},
	isbn = {978-0-387-78934-7},
	url = {http://www.springer.com/mathematics/applications/book/978-0-387-78934-7},
	abstract = {This book on scheduling covers theoretical models as well as scheduling problems in the real world.  The book consists of three parts. The first part focuses on deterministic scheduling with the associated combinatorial problems. ...},
	urldate = {2013-08-03},
	publisher = {Springer},
	author = {Pinedo, Michael L.},
	year = {2008},
	keywords = {Algorithms, Industrial and Production Engineering, Mathematical Programming, Operations Research, Scheduling - Theory, and Systems}
},

@inproceedings{banerjee_sustainable_2009,
	address = {New York, {NY}, {USA}},
	series = {{DAC} '09},
	title = {Sustainable data centers: enabled by supply and demand side management},
	isbn = {978-1-60558-497-3},
	shorttitle = {Sustainable data centers},
	url = {http://doi.acm.org/10.1145/1629911.1630138},
	doi = {10.1145/1629911.1630138},
	abstract = {The environmental impact of data centers is significant and is growing rapidly. Servers alone in the {US} consumed 1.2\% of the nation's energy in 2005, according to the {EPA.} In the following year, the {EPA} found that the cost of energy rose by 10\%. However, there are many opportunities for greater efficiency through integrated design and management of data center components. To that end, we propose a sustainable data center that replaces conventional resource delivery models with a framework centered around the supply and demand side management of all data center resources including {IT}, power and cooling. We have identified five elements for achieving this vision: data center scale lifecycle design, flexible and configurable building blocks, pervasive cross-layer sensing, knowledge discovery and visualization, and autonomous control. We describe these principles and provide selected results that quantify the potential for savings.},
	urldate = {2013-07-26},
	publisher = {{ACM}},
	author = {Banerjee, Prith and Patel, Chandrakant D. and Bash, Cullen and Ranganathan, Parthasarathy},
	year = {2009},
	keywords = {{DC}, data centers, exascale, sustainability},
	pages = {884–887}
},

@article{meisner_powernap_2011,
	title = {The {PowerNap} Server Architecture},
	volume = {29},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/1925109.1925112},
	doi = {10.1145/1925109.1925112},
	abstract = {Data center power consumption is growing to unprecedented levels: the {EPA} estimates {U.S.} data centers will consume 100 billion kilowatt hours annually by 2011. Much of this energy is wasted in idle systems: in typical deployments, server utilization is below 30\%, but idle servers still consume 60\% of their peak power draw. Typical idle periods---though frequent---last seconds or less, confounding simple energy-conservation approaches. In this article, we propose {PowerNap}, an energy-conservation approach where the entire system transitions rapidly between a high-performance active state and a near-zero-power idle state in response to instantaneous load. Rather than requiring fine-grained power-performance states and complex load-proportional operation from individual system components, {PowerNap} instead calls for minimizing idle power and transition time, which are simpler optimization goals. Based on the {PowerNap} concept, we develop requirements and outline mechanisms to eliminate idle power waste in enterprise blade servers. Because {PowerNap} operates in low-efficiency regions of current blade center power supplies, we introduce the Redundant Array for Inexpensive Load Sharing ({RAILS)}, a power provisioning approach that provides high conversion efficiency across the entire range of {PowerNap’s} power demands. Using utilization traces collected from enterprise-scale commercial deployments, we demonstrate that, together, {PowerNap} and {RAILS} reduce average server power consumption by 74\%.},
	number = {1},
	urldate = {2013-07-26},
	journal = {{ACM} Trans. Comput. Syst.},
	author = {Meisner, David and Gold, Brian T. and Wenisch, Thomas F.},
	month = feb,
	year = {2011},
	keywords = {Power management, servers},
	pages = {3:1–3:24}
},

@article{banerjee_towards_2012,
	title = {Towards a net-zero data center},
	volume = {8},
	issn = {1550-4832},
	url = {http://doi.acm.org/10.1145/2367736.2367738},
	doi = {10.1145/2367736.2367738},
	abstract = {A world consisting of billions of service-oriented client devices and thousands of data centers can deliver a diverse range of services, from social networking to management of our natural resources. However, these services must scale in order to meet the fundamental needs of society. To enable such scaling, the total cost of ownership of the data centers that host the services and comprise the vast majority of service delivery costs will need to be reduced. As energy drives the total cost of ownership of data centers, there is a need for a new paradigm in design and management of data centers that minimizes energy used across their lifetimes, from “cradle to cradle”. This tutorial article presents a blueprint for a “net-zero data center”: one that offsets any electricity used from the grid via adequate on-site power generation that gets fed back to the grid at a later time. We discuss how such a data center addresses the total cost of ownership, illustrating that contrary to the oft-held view of sustainability as “paying more to be green”, sustainable data centers—built on a framework that focuses on integrating supply and demand management from end-to-end—can concurrently lead to lowest cost and lowest environmental impact.},
	number = {4},
	urldate = {2013-07-26},
	journal = {J. Emerg. Technol. Comput. Syst.},
	author = {Banerjee, Prithviraj and Patel, Chandrakant and Bash, Cullen and Shah, Amip and Arlitt, Martin},
	month = nov,
	year = {2012},
	pages = {27:1–27:39}
},

@inproceedings{li_temperature_2011,
	address = {Washington, {DC}, {USA}},
	series = {{GREENCOM} '11},
	title = {Temperature, Power, and Makespan Aware Dependent Task Scheduling for Data Centers},
	isbn = {978-0-7695-4466-3},
	url = {http://dx.doi.org/10.1109/GreenCom.2011.12},
	doi = {10.1109/GreenCom.2011.12},
	abstract = {High performance computing data centers are playing increasingly important roles in our daily life. However, as data centers increase in size and number, the power consumption at the data centers has also increased dramatically. We are facing the challenge of reducing energy consumption, lowering down the peak inlet temperature and at the same time meeting short make span requirements. In this paper, we present two dependent task scheduling algorithms to balance the trade-offs among data center's power consumption, peak inlet temperature, and application's make span. We compare them with two existing algorithms, i.e., the List algorithm and the Coolest Inlets algorithms. Our extensive simulations show clear advantages of the proposed approaches over the List and the Coolest Inlets algorithms for both homogeneous and heterogeneous data centers.},
	urldate = {2013-07-26},
	publisher = {{IEEE} Computer Society},
	author = {Li, Zheng and Wang, Li and Ren, Shangping and Quan, Gang},
	year = {2011},
	keywords = {Application Makespan, Consumption, Peak Inlet Temperature, Scheduling Algorithm, Task Dependency},
	pages = {22–27}
},

@inproceedings{moore_weatherman:_2006,
	address = {Washington, {DC}, {USA}},
	series = {{ICAC} '06},
	title = {Weatherman: Automated, Online and Predictive Thermal Mapping and Management for Data Centers},
	isbn = {1-4244-0175-5},
	shorttitle = {Weatherman},
	url = {http://dx.doi.org/10.1109/ICAC.2006.1662394},
	doi = {10.1109/ICAC.2006.1662394},
	urldate = {2013-07-26},
	publisher = {{IEEE} Computer Society},
	author = {Moore, J. and Chase, J. S. and Ranganathan, P.},
	year = {2006},
	pages = {155–164}
},

@inproceedings{patnaik_sustainable_2009,
	address = {New York, {NY}, {USA}},
	series = {{KDD} '09},
	title = {Sustainable operation and management of data center chillers using temporal data mining},
	isbn = {978-1-60558-495-9},
	url = {http://doi.acm.org/10.1145/1557019.1557159},
	doi = {10.1145/1557019.1557159},
	abstract = {Motivation: Data centers are a critical component of modern {IT} infrastructure but are also among the worst environmental offenders through their increasing energy usage and the resulting large carbon footprints. Efficient management of data centers, including power management, networking, and cooling infrastructure, is hence crucial to sustainability. In the absence of a 'first-principles' approach to manage these complex components and their interactions, data-driven approaches have become attractive and tenable. Results: We present a temporal data mining solution to model and optimize performance of data center chillers, a key component of the cooling infrastructure. It helps bridge raw, numeric, time-series information from sensor streams toward higher level characterizations of chiller behavior, suitable for a data center engineer. To aid in this transduction, temporal data streams are first encoded into a symbolic representation, next run-length encoded segments are mined to form frequent motifs in time series, and finally these metrics are evaluated by their contributions to sustainability. A key innovation in our application is the ability to intersperse "don't care" transitions (e.g., transients) in continuous-valued time series data, an advantage we inherit by the application of frequent episode mining to symbolized representations of numeric time series. Our approach provides both qualitative and quantitative characterizations of the sensor streams to the data center engineer, to aid him in tuning chiller operating characteristics. This system is currently being prototyped for a data center managed by {HP} and experimental results from this application reveal the promise of our approach.},
	urldate = {2013-07-26},
	publisher = {{ACM}},
	author = {Patnaik, Debprakash and Marwah, Manish and Sharma, Ratnesh and Ramakrishnan, Naren},
	year = {2009},
	keywords = {chillers, clustering, data centers, frequent episodes, motifs, sustainability},
	pages = {1305–1314}
},

@inproceedings{singh_yank:_2013,
	address = {Berkeley, {CA}, {USA}},
	series = {nsdi'13},
	title = {Yank: enabling green data centers to pull the plug},
	shorttitle = {Yank},
	url = {http://dl.acm.org/citation.cfm?id=2482626.2482642},
	abstract = {Balancing a data center's reliability, cost, and carbon emissions is challenging. For instance, data centers designed for high availability require a continuous flow of power to keep servers powered on, and must limit their use of clean, but intermittent, renewable energy sources. In this paper, we present Yank, which uses a transient server abstraction to maintain server availability, while allowing data centers to "pull the plug" if power becomes unavailable. A transient server's defining characteristic is that it may terminate anytime after a brief advance warning period. Yank exploits the advance warning--on the order of a few seconds--to provide high availability cheaply and efficiently at large scales by enabling each backup server to maintain "live" memory and disk snapshots for many transient {VMs.} We implement Yank inside of Xen. Our experiments show that a backup server can concurrently support up to 15 transient {VMs} with minimal performance degradation with advance warnings as small as 10 seconds, even when {VMs} run memory-intensive interactive web applications.},
	urldate = {2013-07-26},
	publisher = {{USENIX} Association},
	author = {Singh, Rahul and Irwin, David and Shenoy, Prashant and Ramakrishnan, K. K.},
	year = {2013},
	pages = {143–156}
},

@inproceedings{kaushik_t*:_2012,
	address = {Los Alamitos, {CA}, {USA}},
	series = {{SC} '12},
	title = {T*: a data-centric cooling energy costs reduction approach for big data analytics cloud},
	isbn = {978-1-4673-0804-5},
	shorttitle = {\textit{T}},
	url = {http://dl.acm.org/citation.cfm?id=2388996.2389067},
	abstract = {Explosion in Big Data has led to a surge in extremely large-scale Big Data analytics platforms, resulting in burgeoning energy costs. Big Data compute model mandates strong data-locality for computational performance, and moves computations to data. State-of-the-art cooling energy management techniques rely on thermal-aware computational job placement/migration and are inherently data-placement-agnostic in nature. T* takes a novel, data-centric approach to reduce cooling energy costs and to ensure thermal-reliability of the servers. T* is cognizant of the uneven thermal-profile and differences in thermal-reliability-driven load thresholds of the servers, and the differences in the computational jobs arrival rate, size, and evolution life spans of the Big Data placed in the cluster. Based on this knowledge, and coupled with its predictive file models and insights, T* does proactive, thermal-aware file placement, which implicitly results in thermal-aware job placement in the Big Data analytics compute model. Evaluation results with one-month long real-world Big Data analytics production traces from Yahoo! show up to 42\% reduction in the cooling energy costs with T* courtesy of its lower and more uniform thermal-profile and 9x better performance than the state-of-the-art data-agnostic cooling techniques.},
	urldate = {2013-07-22},
	publisher = {{IEEE} Computer Society Press},
	author = {Kaushik, Rini T. and Nahrstedt, Klara},
	year = {2012},
	keywords = {Temperature Set Point Adjustment (Standalone), Temperature Set Point Adjustment (Synergy between cooling and {IT} Equipment)},
	pages = {52:1–52:11}
}
